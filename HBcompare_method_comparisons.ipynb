{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18127,"status":"ok","timestamp":1666066583205,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"},"user_tz":240},"id":"MThirJJyZbk5","outputId":"3b4411c4-dd7b-4467-8be0-91bf42a6534c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content\n","/content/gdrive/My Drive/Graph_based_methods/Graph_Transformer\n"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","import os\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","!pwd\n","os.chdir('gdrive/My Drive/Graph_based_methods/Graph_Transformer/')\n","!pwd"]},{"cell_type":"markdown","metadata":{"id":"_wcxO_Hxpyhb"},"source":["### Util"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3387,"status":"ok","timestamp":1666066586590,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"},"user_tz":240},"id":"dCquw44_p0Uj","outputId":"8767fd11-7c31-4542-be56-25a1c4b0cff6"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading data\n","# classes: 2\n","# maximum node tag: 3\n","# data: 60\n"]}],"source":["from __future__ import print_function\n","import networkx as nx\n","import numpy as np\n","import random\n","import scipy.sparse as sp\n","from sklearn.model_selection import StratifiedKFold\n","from scipy.sparse import isspmatrix\n","\n","\"\"\"Adapted from https://github.com/weihua916/powerful-gnns/blob/master/util.py\"\"\"\n","\n","class S2VGraph(object):\n","    def __init__(self, g, label, node_tags=None, node_features=None):\n","        '''\n","            g: a networkx graph\n","            label: an integer graph label\n","            node_tags: a list of integer node tags\n","            node_features: a torch float tensor, one-hot representation of the tag that is used as input to neural nets\n","            edge_mat: a torch long tensor, contain edge list, will be used to create torch sparse tensor\n","            neighbors: list of neighbors (without self-loop)\n","        '''\n","        self.label = label\n","        self.g = g\n","        self.node_tags = node_tags\n","        self.neighbors = []\n","        self.node_features = 0\n","        self.edge_mat = 0\n","        self.max_neighbor = 0\n","\n","\n","def load_data(dataset, degree_as_tag):\n","    '''\n","        dataset: name of dataset\n","        test_proportion: ratio of test train split\n","        seed: random seed for random splitting of dataset\n","    '''\n","\n","    print('loading data')\n","    g_list = []\n","    label_dict = {}\n","    feat_dict = {}\n","\n","    with open('/content/gdrive/My Drive/Graph_based_methods/Graph_Transformer/dataset/%s/%s.txt' % (dataset, dataset), 'r') as f:\n","        n_g = int(f.readline().strip())\n","        for i in range(n_g):\n","            row = f.readline().strip().split()\n","            n, l = [int(w) for w in row]\n","            if not l in label_dict:\n","                mapped = len(label_dict)\n","                label_dict[l] = mapped\n","            g = nx.Graph()\n","            node_tags = []\n","            node_features = []\n","            n_edges = 0\n","            for j in range(n):\n","                g.add_node(j)\n","                row = f.readline().strip().split()\n","                tmp = int(row[1]) + 2\n","                if tmp == len(row):\n","                    # no node attributes\n","                    row = [int(w) for w in row]\n","                    attr = None\n","                else:\n","                    row, attr = [int(w) for w in row[:tmp]], np.array([float(w) for w in row[tmp:]])\n","                if not row[0] in feat_dict:\n","                    mapped = len(feat_dict)\n","                    feat_dict[row[0]] = mapped\n","                node_tags.append(feat_dict[row[0]])\n","\n","                if tmp > len(row):\n","                    node_features.append(attr)\n","\n","                n_edges += row[1]\n","                for k in range(2, len(row)):\n","                    g.add_edge(j, row[k])\n","\n","            if node_features != []:\n","                node_features = np.stack(node_features)\n","                node_feature_flag = True\n","            else:\n","                node_features = None\n","                node_feature_flag = False\n","\n","            assert len(g) == n\n","\n","            g_list.append(S2VGraph(g, l, node_tags))\n","     \n","\n","    #add labels and edge_mat       \n","    for g in g_list:\n","        g.neighbors = [[] for i in range(len(g.g))]\n","        for i, j in g.g.edges():\n","            g.neighbors[i].append(j)\n","            g.neighbors[j].append(i)\n","        degree_list = []\n","        for i in range(len(g.g)):\n","            g.neighbors[i] = g.neighbors[i]\n","            degree_list.append(len(g.neighbors[i]))\n","        g.max_neighbor = max(degree_list)\n","\n","        g.label = label_dict[g.label]\n","\n","        edges = [list(pair) for pair in g.g.edges()]\n","        edges.extend([[i, j] for j, i in edges])\n","\n","        deg_list = list(dict(g.g.degree(range(len(g.g)))).values())\n","\n","        g.edge_mat = np.transpose(np.array(edges, dtype=np.int32), (1,0))\n","\n","    if degree_as_tag:\n","        for g in g_list:\n","            g.node_tags = list(dict(g.g.degree).values())\n","\n","    #Extracting unique tag labels   \n","    tagset = set([])\n","    for g in g_list:\n","        tagset = tagset.union(set(g.node_tags))\n","\n","    tagset = list(tagset)\n","    tag2index = {tagset[i]:i for i in range(len(tagset))}\n","\n","    for g in g_list:\n","        g.node_features = np.zeros((len(g.node_tags), len(tagset)), dtype=np.float32)\n","        g.node_features[range(len(g.node_tags)), [tag2index[tag] for tag in g.node_tags]] = 1\n","\n","\n","    print('# classes: %d' % len(label_dict))\n","    print('# maximum node tag: %d' % len(tagset))\n","\n","    print(\"# data: %d\" % len(g_list))\n","\n","    return g_list, len(label_dict)\n","\n","\n","\"\"\"Convert sparse matrix to tuple representation.\"\"\"\n","def sparse_to_tuple(sparse_mx):\n","    def to_tuple(mx):\n","        if not sp.isspmatrix_coo(mx):\n","            mx = mx.tocoo()\n","        coords = np.vstack((mx.row, mx.col)).transpose()\n","        values = mx.data\n","        shape = mx.shape\n","        return coords, values, shape\n","\n","    if isinstance(sparse_mx, list):\n","        for i in range(len(sparse_mx)):\n","            sparse_mx[i] = to_tuple(sparse_mx[i])\n","    else:\n","        sparse_mx = to_tuple(sparse_mx)\n","\n","    return sparse_mx\n"]},{"cell_type":"markdown","source":["### Set up dataset data"],"metadata":{"id":"PuLn2om5T1gk"}},{"cell_type":"code","source":["data_with_ = \"dataset_2\"\n","data_without_ = \"dataset2\"\n","data_name = data_without_\n","use_degree_as_tag = False\n","\n","graphs, num_classes = load_data(data_name, use_degree_as_tag)\n","\n","os.chdir('/content/gdrive/My Drive/Graph_based_methods/Graph_Transformer/dataset/Features_Omar_new')\n","\n","dataset = data_with_\n","# dataset_name = dataset + '_RBF_plus_connectivity_manual_matrix.mat'\n","# dataset_name = dataset + '_RBF_manual_matrix.mat'\n","# dataset_name = dataset + '_label_embedding_matrix.mat'\n","dataset_name = dataset + '_connectivity_matrix.mat'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2AJO_qATxnv","executionInfo":{"status":"ok","timestamp":1666068317854,"user_tz":240,"elapsed":180,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"}},"outputId":"48b0cb7a-66ac-425b-ea91-6c8910c38612"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data\n","# classes: 2\n","# maximum node tag: 3\n","# data: 80\n"]}]},{"cell_type":"markdown","metadata":{"id":"y45Q0HJanW8L"},"source":["### KNN Classifier"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qan0fFSYnX_6","executionInfo":{"status":"ok","timestamp":1666066586591,"user_tz":240,"elapsed":3,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"}}},"outputs":[],"source":["def Knn_classifier(X, label_all, train_idx, test_idx):\n","  X_train = X[train_idx,:]\n","  X_test = X[test_idx,:]\n","  train_label = label_all[train_idx]\n","  test_label = label_all[test_idx]\n","\n","  num_test = len(list(test_idx))\n","  num_train = len(list(train_idx))\n","\n","  predict_labels = []\n","\n","  for i in range(num_test):\n","    X_test_i = X_test[i,:]\n","    dist_i = []\n","    for j in range(num_train):\n","      X_train_j = X_train[j,:]\n","      dist_ij = np.linalg.norm(X_test_i - X_train_j)\n","      dist_i.append(dist_ij)\n","\n","    min_idx = np.argmin(np.array(dist_i))\n","    label_i = train_label[min_idx]\n","    predict_labels.append(label_i)\n","\n","  return predict_labels \n"]},{"cell_type":"markdown","metadata":{"id":"lHd7IYzkkdsm"},"source":["### Visualize Feature"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"uJz5_e95uwYZ","executionInfo":{"status":"ok","timestamp":1666066587713,"user_tz":240,"elapsed":1124,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"}}},"outputs":[],"source":["from matplotlib import pyplot as plt\n","import time\n","import numpy as np\n","import pandas as pd\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","import seaborn as sns\n","from sklearn.datasets import fetch_openml\n","from sklearn import datasets\n","import matplotlib.pylab as plt\n","import scipy.sparse as sparse\n","\n","def visualize_with_tSNE(X, labels):\n","  classes = np.unique(labels)\n","  num_classes = classes.size \n","  y = labels\n","\n","  tsne = TSNE(n_components=2, random_state=0)\n","\n","  X_2d = tsne.fit_transform(X)\n","\n","  target_ids = range(num_classes)\n","  label_name = np.array(range(num_classes))\n","\n","\n","  plt.figure(figsize=(6, 5))\n","  colors = 'r', 'g', 'b', 'c', 'm', 'y', 'k', 'w', 'orange', 'purple'\n","  for i, c, label in zip(target_ids, colors, label_name):\n","      if(i == 0):\n","        marker_label = '^'\n","        str_label = 'Class: 0'\n","      if(i == 1):\n","        marker_label = 'o'  \n","        str_label = 'Class: 1'\n","      if(i == 2):\n","        marker_label = '+'  \n","        str_label = 'Class: 2'\n","      if(i == 3):\n","        marker_label = '*'  \n","        str_label = 'Class: 3'      \n","      plt.scatter(X_2d[y == i, 0], X_2d[y == i, 1], marker = marker_label ,c=c, label= str(str_label))\n","  plt.legend()\n","  plt.show()\n","\n","\n","# # create a sparse diagonal matrix with ones on the diagonal\n","# A = sparse.eye(100)\n","# # visualize the sparse matrix with Spy\n","# plt.spy(A, markersize=2)\n","\n","# num_graphs,_,_ = X_feature.shape\n","\n","# for i in range(num_graphs):\n","#   X_feature_i = X_feature[10,:,:]\n","#   plt.spy(X_feature_i, markersize=2)"]},{"cell_type":"markdown","metadata":{"id":"lTizzhHQLLi0"},"source":["### FCN Classify"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5942,"status":"ok","timestamp":1666066593653,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"},"user_tz":240},"id":"VkPOeGPHLM80","outputId":"2e7f0353-f69f-4a5d-f4b1-d0303f0a1fae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keract\n","  Downloading keract-4.5.1-py3-none-any.whl (12 kB)\n","Installing collected packages: keract\n","Successfully installed keract-4.5.1\n"]}],"source":["!pip install keract\n","\n","import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy.io\n","from keras import backend as K\n","from keract import get_activations\n","import keract\n","\n","def FCN_classify(X_train, X_test, label_train, label_test, num_classes):\n","  model = models.Sequential()\n","  model.add(layers.Dense(64, activation='softmax'))\n","  model.add(layers.Dense(num_classes))\n","\n","  # model.summary()\n","\n","  model.compile(optimizer='adam',\n","                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                metrics=['accuracy'])\n","  \n","  history = model.fit(X_train, label_train, epochs=19, verbose =0)\n","\n","  predictions = model.predict(X_test)\n","\n","  predicted_labales = np.argmax(predictions, axis = 1)\n","\n","  # print(' acc ', acc, ' auc ', auc) \n","  return predicted_labales\n","\n","  \n","  \n"]},{"cell_type":"markdown","metadata":{"id":"XWTNBL8QntFV"},"source":["### Cal_metrics"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"z8gJ4l4onumN","executionInfo":{"status":"ok","timestamp":1666066593654,"user_tz":240,"elapsed":10,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"}}},"outputs":[],"source":[", f1_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn import preprocessing\n","from sklearn.model_selection import StratifiedKFold\n","from scipy.sparse import isspmatrix\n","from sklearn.linear_model import LogisticRegression\n","\n","\n","\"\"\"Get indexes of train and test sets\"\"\"\n","def separate_data_idx(label_all, fold_idx, seed=0):\n","    assert 0 <= fold_idx and fold_idx < 10, \"fold_idx must be from 0 to 9.\"\n","    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n","\n","    labels = label_all\n","    idx_list = []\n","\n","    for idx in skf.split(np.zeros(len(labels)), labels):\n","        idx_list.append(idx)\n","    train_idx, test_idx = idx_list[fold_idx]\n","\n","    return train_idx, test_idx\n","\n","\n","def calculate_acc(predicted, gt):\n","  correct = 0\n","  for i in range(len(predicted)):\n","    if(predicted[i] == gt[i]):\n","      correct += 1\n","\n","  acc = correct/len(predicted)\n","\n","\n","  lb = preprocessing.LabelBinarizer()\n","  lb.fit(gt)\n","\n","  gt_binary = lb.transform(gt)\n","  predicted_binary = lb.transform(predicted)\n","\n","  auc = roc_auc_score(gt_binary, predicted_binary, average = 'macro')\n","  precision, recall, f1score, support = precision_recall_fscore_support(gt_binary, predicted_binary, average = 'macro')\n","\n","  A = classification_report(predicted, gt, digits = 4)\n","  print(A)\n","\n","\n","  return acc, auc, precision, recall, f1score    "]},{"cell_type":"markdown","metadata":{"id":"F5CN2etPIXdR"},"source":["### Data Preprocessing"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"5E2eH-GEIa43","executionInfo":{"status":"ok","timestamp":1666066593654,"user_tz":240,"elapsed":10,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"}}},"outputs":[],"source":["### PCA\n","import numpy as np\n","\n","def Feature_reduction_PCA(X, R):\n","  mean_X = np.mean(X,axis=0)\n","  X_normalize = X - mean_X\n","  U, S, V_T = np.linalg.svd(X_normalize, full_matrices=False)\n","  V = np.transpose(V_T)\n","  V_truncate = V[:,0:R]\n","  X_Feature = np.matmul(X_normalize,V_truncate)\n","\n","  return X_Feature\n","\n","def Vec2Matrix(X):\n","  num_graphs, M_square = X.shape \n","  M_matrix = int(np.sqrt(M_square))\n","  X_matrix = np.zeros([num_graphs, int(np.sqrt(M_square)), int(np.sqrt(M_square))])\n","  for i in range(num_graphs):\n","    Xi = X[i,:]\n","    Xi_matrix = np.reshape(Xi, [M_matrix, M_matrix])\n","    X_matrix[i,:,:] = Xi_matrix\n","\n","  return X_matrix\n","\n","### 2DPCA\n","def Feature_reduction_2DPCA(X,R):\n","  X_new = X.copy()\n","  N_graphs,_,_ = X.shape\n","  sum_X = 0\n","  for i in range(N_graphs):\n","    sum_X = sum_X + X[i,:,:]\n","\n","  mean_X = sum_X/N_graphs\n","\n","  for i in range(N_graphs):\n","    X_new[i,:,:] = X[i,:,:] - mean_X\n","\n","  sum_X = 0\n","\n","  for i in range(N_graphs):\n","    Xi = X_new[i,:,:]\n","    sum_X = sum_X + np.matmul(Xi, Xi.transpose())\n","\n","  U,S,V_t = np.linalg.svd(sum_X)\n","  U = U[:,0:R]\n","  X_new_feature = np.zeros([N_graphs,R,R])\n","\n","  for i in range(N_graphs):\n","    Xi = X_new[i,:,:]\n","    Xi = np.matmul(U.transpose(),Xi)  \n","    Xi = np.matmul(Xi,U)  \n","    X_new_feature[i,:,:] = Xi\n","\n","\n","  return X_new_feature  \n","\n","def Matrix2Vec(X):\n","  N, M1,M2 = X.shape\n","  X_vector = np.zeros([N, M1*M2])\n","  for i in range(N):\n","    Xi = X[i,:,:]\n","    Xi_vector = np.reshape(Xi,[1, M1*M2])\n","    X_vector[i,:] = Xi_vector\n","\n","  return X_vector \n","\n","def permute_matrix(X, ratio):\n","  size_X,_ = X.shape \n","  A = np.eye(size_X)\n","  select_num = int(size_X * ratio)\n","  perm_index = np.random.permutation(size_X)   \n","  selected_index = perm_index[0:select_num]\n","  A[selected_index,:] = A[np.random.permutation(selected_index),:];\n","\n","  permuted_X = np.matmul(np.matmul(A,X), A.transpose())\n","\n","  return permuted_X, A\n","\n","def load_and_process_node_features(data_name, use_degree_as_tag):  \n","    graphs, num_classes = load_data(data_name, use_degree_as_tag)\n","    min_num_nodes = 100000\n","    num_graphs = len(graphs)\n","    for i in range(num_graphs):\n","      graph_i = graphs[i]\n","      graph_i_feature = graph_i.node_features\n","      num_nodes,feature_size = graph_i_feature.shape\n","      if(num_nodes < min_num_nodes):\n","        min_num_nodes = num_nodes\n","\n","    feature_all_selected = np.zeros([num_graphs,min_num_nodes*feature_size])  \n","\n","    for i in range(num_graphs):\n","      graph_i = graphs[i]\n","      graph_i_feature = graph_i.node_features.copy()\n","      graph_i_feature_selected = graph_i_feature[0:min_num_nodes,:]\n","      graph_i_feature_vector = np.reshape(graph_i_feature_selected, [1,min_num_nodes*feature_size])\n","      feature_all_selected[i,:] = graph_i_feature_vector  \n","\n","    return feature_all_selected\n","\n","# data_name = \"dataset1\"\n","# use_degree_as_tag = False\n","\n","# feature_all_selected = load_and_process_node_features(data_name, use_degree_as_tag)"]},{"cell_type":"markdown","metadata":{"id":"Mi52pXK6dbzW"},"source":["###Print Results"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"5ObJPKUvGZ6k","executionInfo":{"status":"ok","timestamp":1666066593654,"user_tz":240,"elapsed":9,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"}}},"outputs":[],"source":["from numpy import std\n","def print_results(total_acc, total_auc, total_f1score):\n","  print(\"Accuracy from all runs: \", total_acc)\n","  print(\"AUC from all runs: \",total_auc)\n","  total = 0\n","  count = 0\n","  for i in range(len(total_acc)):\n","    for each in total_acc[i]:\n","      total += each\n","      count += 1\n","  print(\"Average acc = \", total/count)\n","  print(\"STD = \", std(total_acc))\n","\n","  total = 0\n","  count = 0\n","  for i in range(len(total_auc)):\n","    for each in total_auc[i]:\n","      total += each\n","      count += 1\n","  print(\"Average auc = \", total/count)\n","  print(\"STD = \", std(total_auc))\n","\n","  total = 0\n","  count = 0\n","  for i in range(len(total_f1score)):\n","    for each in total_f1score[i]:\n","      total += each\n","      count += 1\n","  print(\"Average f1score = \", total/count)\n","  print(\"STD = \", std(total_f1score))"]},{"cell_type":"markdown","metadata":{"id":"xg-e8cPJk2Fh"},"source":["### Graph Kernel Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14832,"status":"ok","timestamp":1665954292698,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"},"user_tz":240},"id":"2KuK6dnWcvo5","outputId":"beb46704-2c26-4b31-f4fe-d288511ff2b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting grakel\n","  Downloading grakel-0.1.8-cp37-cp37m-manylinux2010_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 9.4 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.7/dist-packages (from grakel) (1.0.2)\n","Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from grakel) (0.16.0)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from grakel) (1.21.6)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from grakel) (0.29.32)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from grakel) (1.2.0)\n","Collecting nose>=1.1.2\n","  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n","\u001b[K     |████████████████████████████████| 154 kB 65.4 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from grakel) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19->grakel) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19->grakel) (1.7.3)\n","Installing collected packages: nose, grakel\n","Successfully installed grakel-0.1.8 nose-1.3.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sklearn\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.2.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n","Building wheels for collected packages: sklearn\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=36878129db27683eaf46c12aff11d2aba02852e85f49912390895628dbc90be9\n","  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","Successfully built sklearn\n","Installing collected packages: sklearn\n","Successfully installed sklearn-0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n","  if __name__ == '__main__':\n"]}],"source":["!pip install grakel\n","!pip install sklearn\n","\n","import networkx as nx\n","import numpy as np\n","from scipy.sparse import spmatrix\n","\n","from warnings import warn\n","from collections import Counter, Iterable\n","from grakel import Kernel, Graph"]},{"cell_type":"markdown","metadata":{"id":"GTWAzqOuq3jf"},"source":["### Graph Kernel Method\n","\n","** This method does not work at this time.\n","Applies grakel methods to a list of adjacency matrix representations of graphs."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":675},"executionInfo":{"elapsed":3601,"status":"error","timestamp":1665954479686,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"},"user_tz":240},"id":"80_Dpr0Vk1rM","outputId":"fd12cd2c-6402-4d44-ad62-96a3ae806467"},"outputs":[{"output_type":"stream","name":"stdout","text":["Labels\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n"," 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n"," 4 4 4 4 4 4 4 4 4 4 4]\n","Example matrix in X_feature\n","[[1. 1. 0. ... 0. 0. 0.]\n"," [1. 1. 0. ... 0. 0. 0.]\n"," [0. 0. 1. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","*********** dataset_name = dataset_3_connectivity_matrix.mat  *******************\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-136c62b4e882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;31m# run_gk()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   \u001b[0macc_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauc_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1score_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_gk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m   \u001b[0mtotal_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m   \u001b[0mtotal_auc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-136c62b4e882>\u001b[0m in \u001b[0;36mrun_gk\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;31m# cls.fit(train_embeddings, train_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m   \u001b[0mACC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             )\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n","\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'Graph'"]}],"source":["from grakel.kernels.graphlet_sampling import GraphletSampling\n",", train_test_split\n","import numpy as np\n","import scipy.io\n","import scipy.sparse\n","import os\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split\n","from grakel import GraphKernel, ShortestPath, Graph\n","from grakel.kernels import WeisfeilerLehman, VertexHistogram\n","from grakel.datasets import fetch_dataset\n","from grakel.utils import cross_validate_Kfold_SVM\n","\n","# MUTAG = fetch_dataset(\"MUTAG\", verbose=False)\n","# G = MUTAG.data\n","# y = MUTAG.target\n","# print(G)\n","# print(y)\n","\n","# wl_kernel = WeisfeilerLehman(n_iter=5, normalize=True, base_graph_kernel=VertexHistogram)\n","# G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=0.1, random_state=42)\n","\n","# print(G_train)\n","\n","os.chdir('/content/gdrive/My Drive/Graph_based_methods/Graph_Transformer/dataset/Features_Omar_new')\n","\n","data_with_ = \"dataset_3\"\n","data_without_ = \"dataset3\"\n","\n","dataset = data_with_\n","data_name = data_without_\n","use_degree_as_tag = False\n","# dataset_name = dataset + '_RBF_plus_connectivity_manual_matrix.mat'\n","# dataset_name = dataset + '_RBF_manual_matrix.mat'\n","# dataset_name = dataset + '_label_embedding_matrix.mat'\n","dataset_name = dataset + '_connectivity_matrix.mat'\n","\n","mat = scipy.io.loadmat(dataset_name)\n","X = mat['X_feature_tensor']\n","ndims_X = np.ndim(X)\n","\n","# if(ndims_X == 3):\n","#   X = Matrix2Vec(X)\n","\n","# X_feature = X\n","\n","label_name = 'label_'+ dataset + '.mat'\n","mat = scipy.io.loadmat(label_name)\n","label_all = mat['label_all'][0]\n","classes = np.unique(label_all)\n","num_classes = classes.size\n","\n","print(\"Labels\")\n","print(label_all)\n","print(\"Example matrix in X_feature\")\n","print(X[5])\n","\n","all_graphs = []\n","for i in X:\n","  sparse_mat = sparse.csr_matrix(i)\n","  graph = Graph(sparse_mat, node_labels = label_all)\n","  all_graphs.append(graph)\n","\n","def run_gk():\n","  # visualize_with_tSNE(X_feature, label_all)\n","\n","  print('*********** dataset_name =', dataset_name,' *******************')\n","\n","  predicted_labels = []\n","  acc_all = []\n","  auc_all = []\n","  f1score_all = []\n","\n","  ##**** Logistic Regression **** #####\n","  # for fold_idx in range(5):\n","      # train_idx, test_idx = separate_data_idx(label_all, fold_idx)\n","      # train_embeddings = X_feature[train_idx,:]\n","      # test_embeddings = X_feature[test_idx,:]\n","      # train_labels = label_all[train_idx]\n","      # test_labels = label_all[test_idx]\n","\n","  G_train, G_test, y_train, y_test = train_test_split(all_graphs, label_all, test_size=0.1)\n","\n","  #GK transform\n","  # gk = WeisfeilerLehman(base_graph_kernel = VertexHistogram, normalize=True)\n","  # gk = ShortestPath(normalize=True, with_labels=False)\n","  # gk = GraphletSampling(normalize=True)\n","\n","  # for i in G_train:\n","  # K_train = gk.fit_transform(G_train)\n","  # K_test = gk.transform(G_test)\n","\n","  # cls = LogisticRegression(tol=0.001, max_iter = 2000)\n","  # cls.fit(train_embeddings, train_labels)\n","  cls = svm.SVC(kernel=\"linear\")\n","  cls.fit(G_train, y_train)\n","  ACC = cls.score(G_test, y_test)\n","\n","  predicted = cls.predict(G_test)\n","  print(predicted)\n","\n","  acc, auc, precision, recall, f1score = calculate_acc(predicted, y_test)\n","\n","  print(' acc ', acc, ' auc ', auc, ' precision ', precision, ' recall ', recall, ' f1score ', f1score) \n","\n","  \n","  acc_all.append(acc)\n","  auc_all.append(auc)\n","  f1score_all.append(f1score)\n","\n","  acc_all = np.array(acc_all)\n","  auc_all = np.array(auc_all)\n","  f1score_all = np.array(f1score_all)\n","\n","  # print('acc_all = ', acc_all)   \n","\n","  # print('auc_all = ', auc_all) \n","  \n","  return acc_all, auc_all, f1score_all\n","\n","total_acc = []\n","total_auc = []\n","total_f1score = []\n","iter = 1\n","for i in range(iter):\n","  # run_gk()\n","  acc_all,auc_all, f1score_all = run_gk()\n","  total_acc.append(acc_all)\n","  total_auc.append(auc_all)\n","  total_f1score.append(f1score_all)\n","\n","# print_results(total_acc, total_auc, total_f1score)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":196,"status":"ok","timestamp":1664925716465,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"},"user_tz":240},"id":"XVYx2d8JTe6_","outputId":"14364f22-4677-402b-85c2-b05cdcc65bdf"},"outputs":[{"name":"stdout","output_type":"stream","text":["ACC: 0.145\n"]}],"source":["print(\"ACC:\", np.mean(total_acc))"]},{"cell_type":"markdown","source":["### GK Linear Kernel\n","\n","This method applies a linear kernel to the adjacency matrix representing the overall graph."],"metadata":{"id":"qD2eFV1UnYx1"}},{"cell_type":"code","source":["import numpy as np\n","import scipy.io\n","import os\n","from sklearn import svm\n","\n","os.chdir('/content/gdrive/My Drive/Graph_based_methods/Graph_Transformer/dataset/Features_Omar_new')\n","\n","data_with_ = \"dataset_5\"\n","data_without_ = \"dataset5\"\n","dataset = data_with_\n","data_name = data_without_\n","use_degree_as_tag = False\n","# dataset_name = dataset + '_RBF_plus_connectivity_manual_matrix.mat'\n","# dataset_name = dataset + '_RBF_manual_matrix.mat'\n","# dataset_name = dataset + '_label_embedding_matrix.mat'\n","dataset_name = dataset + '_connectivity_matrix.mat'\n","\n","def run_PCA():\n","  # random.seed()\n","  mat = scipy.io.loadmat(dataset_name)\n","  X = mat['X_feature_tensor']\n","\n","  ndims_X = np.ndim(X)\n","\n","  if(ndims_X == 3):\n","    X = Matrix2Vec(X)\n","\n","  X_feature = X\n","\n","  label_name = 'label_'+ dataset + '.mat'\n","  mat = scipy.io.loadmat(label_name)\n","  label_all = mat['label_all'][0]\n","  classes = np.unique(label_all)\n","  num_classes = classes.size\n","\n","  # visualize_with_tSNE(X_feature, label_all)\n","\n","  print('*********** dataset_name =', dataset_name,' *******************')\n","\n","  predicted_labels = []\n","  acc_all = []\n","  auc_all = []\n","  f1score_all = []\n","\n","\n","  ##**** Logistic Regression **** #####\n","  for fold_idx in range(5):\n","      train_idx, test_idx = separate_data_idx(label_all, fold_idx)\n","      train_embeddings = X_feature[train_idx,:]\n","      test_embeddings = X_feature[test_idx,:]\n","      train_labels = label_all[train_idx]\n","      test_labels = label_all[test_idx]\n","\n","      # cls = LogisticRegression(tol=0.001, max_iter = 2000)\n","      cls = svm.SVC(kernel=\"linear\")\n","      cls.fit(train_embeddings, train_labels)\n","      ACC = cls.score(test_embeddings, test_labels)\n","\n","      predicted = cls.predict(test_embeddings)\n","      predicted_labels.append(predicted)\n","\n","      acc, auc, precision, recall, f1score = calculate_acc(predicted, test_labels)\n","\n","      print('fold ', fold_idx, ' acc ', ACC, ' auc ', auc, ' precision ', precision, ' recall ', recall, ' f1score ', f1score) \n","\n","      \n","      acc_all.append(acc)\n","      auc_all.append(auc)\n","      f1score_all.append(f1score)\n","\n","  acc_all = np.array(acc_all)\n","  auc_all = np.array(auc_all)\n","  f1score_all = np.array(f1score_all)\n","\n","  # print('acc_all = ', acc_all)   \n","\n","  # print('auc_all = ', auc_all) \n","  \n","  return acc_all, auc_all, f1score_all\n","\n","total_acc = []\n","total_auc = []\n","total_f1score = []\n","iter = 1\n","for i in range(iter):\n","  acc_all,auc_all, f1score_all = run_PCA()\n","  total_acc.append(acc_all)\n","  total_auc.append(auc_all)\n","  total_f1score.append(f1score_all)\n","\n","print_results(total_acc, total_auc, total_f1score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WmipNaWhnZDu","executionInfo":{"status":"ok","timestamp":1665955697830,"user_tz":240,"elapsed":4982,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"}},"outputId":"490c96bd-895d-4f79-cbca-ea9f62ac0b4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["*********** dataset_name = dataset_5_connectivity_matrix.mat  *******************\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.8000    0.8000         5\n","           1     0.8000    0.8000    0.8000         5\n","\n","    accuracy                         0.8000        10\n","   macro avg     0.8000    0.8000    0.8000        10\n","weighted avg     0.8000    0.8000    0.8000        10\n","\n","fold  0  acc  0.8  auc  0.8  precision  0.8  recall  0.8  f1score  0.8000000000000002\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.5714    0.6667         7\n","           1     0.4000    0.6667    0.5000         3\n","\n","    accuracy                         0.6000        10\n","   macro avg     0.6000    0.6190    0.5833        10\n","weighted avg     0.6800    0.6000    0.6167        10\n","\n","fold  1  acc  0.6  auc  0.6  precision  0.6190476190476191  recall  0.6000000000000001  f1score  0.5833333333333333\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.6667    0.7273         6\n","           1     0.5000    0.6667    0.5714         3\n","\n","    accuracy                         0.6667         9\n","   macro avg     0.6500    0.6667    0.6494         9\n","weighted avg     0.7000    0.6667    0.6753         9\n","\n","fold  2  acc  0.6666666666666666  auc  0.6500000000000001  precision  0.6666666666666666  recall  0.65  f1score  0.6493506493506493\n","              precision    recall  f1-score   support\n","\n","           0     0.4000    0.6667    0.5000         3\n","           1     0.7500    0.5000    0.6000         6\n","\n","    accuracy                         0.5556         9\n","   macro avg     0.5750    0.5833    0.5500         9\n","weighted avg     0.6333    0.5556    0.5667         9\n","\n","fold  3  acc  0.5555555555555556  auc  0.575  precision  0.5833333333333333  recall  0.575  f1score  0.55\n","              precision    recall  f1-score   support\n","\n","           0     0.7500    0.6000    0.6667         5\n","           1     0.6000    0.7500    0.6667         4\n","\n","    accuracy                         0.6667         9\n","   macro avg     0.6750    0.6750    0.6667         9\n","weighted avg     0.6833    0.6667    0.6667         9\n","\n","fold  4  acc  0.6666666666666666  auc  0.675  precision  0.675  recall  0.675  f1score  0.6666666666666665\n","Accuracy from all runs:  [array([0.8       , 0.6       , 0.66666667, 0.55555556, 0.66666667])]\n","AUC from all runs:  [array([0.8  , 0.6  , 0.65 , 0.575, 0.675])]\n","Average acc =  0.6577777777777777\n","STD =  0.08267144550105901\n","Average auc =  0.6599999999999999\n","STD =  0.07842193570679064\n","Average f1score =  0.6498701298701298\n","STD =  0.08628158499614494\n"]}]},{"cell_type":"markdown","source":["### GK Kernel Pre-computed\n","\n","**This method does not work at this time.\n","\n","This function takes a pre-computed kernel matrix and inputs into a 5-fold CV with SVM classifier. \n"],"metadata":{"id":"zWn6veyhwIKV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"F2rJoV1eaXyj","colab":{"base_uri":"https://localhost:8080/","height":658},"executionInfo":{"status":"error","timestamp":1665373640677,"user_tz":240,"elapsed":1366,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"}},"outputId":"1c8b4056-7786-4f3e-c791-7a6c645cd54f"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** dataset_name = dataset_1_connectivity_matrix.mat  *******************\n","training...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:214: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  if self.kernel == \"precomputed\" and n_samples != X.shape[1]:\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  if kernel == \"precomputed\":\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:333: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  random_seed=random_seed,\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-74aa584893ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0;31m# run_gk()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m   \u001b[0macc_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauc_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1score_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_gk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m   \u001b[0mtotal_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0mtotal_auc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-50-74aa584893ba>\u001b[0m in \u001b[0;36mrun_gk\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m       \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m       \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32msklearn/svm/_libsvm.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm.fit\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: array([[467601., 463115., 453584., ..., 464609., 462297., 467506.],\n       [463115., 458828., 449575., ..., 460179., 458010., 462937.],\n       [453584., 449575., 442387., ..., 451607., 449182., 454290.],\n       ...,\n       [464609., 460179., 451607., ..., 462098., 459582., 465021.],\n       [462297., 458010., 449182., ..., 459582., 457303., 462365.],\n       [467506., 462937., 454290., ..., 465021., 462365., 468063.]]) is not in list"]}],"source":["from grakel.kernels.graphlet_sampling import GraphletSampling\n",", train_test_split\n","import numpy as np\n","import scipy.io\n","import scipy.sparse\n","import os\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split\n","from grakel import GraphKernel, ShortestPath, Graph\n","from grakel.kernels import WeisfeilerLehman, VertexHistogram\n","from grakel.datasets import fetch_dataset\n","from grakel.utils import cross_validate_Kfold_SVM\n","\n","\n","os.chdir('/content/gdrive/My Drive/Graph_based_methods/Graph_Transformer/dataset/dataset1')\n","kernel_name = dataset + '_SPkernel.mat'\n","kernel_mat = scipy.io.loadmat(kernel_name)\n","kernel = kernel_mat['Kernel']\n","\n","os.chdir('/content/gdrive/My Drive/Graph_based_methods/Graph_Transformer/dataset/Features_Omar_new')\n","\n","data_with_ = \"dataset_1\"\n","data_without_ = \"dataset1\"\n","\n","dataset = data_with_\n","data_name = data_without_\n","use_degree_as_tag = False\n","# dataset_name = dataset + '_RBF_plus_connectivity_manual_matrix.mat'\n","# dataset_name = dataset + '_RBF_manual_matrix.mat'\n","# dataset_name = dataset + '_label_embedding_matrix.mat'\n","dataset_name = dataset + '_connectivity_matrix.mat'\n","\n","mat = scipy.io.loadmat(dataset_name)\n","X = mat['X_feature_tensor']\n","ndims_X = np.ndim(X)\n","\n","if(ndims_X == 3):\n","  X = Matrix2Vec(X)\n","\n","X_feature = X\n","X_feature = kernel\n","\n","label_name = 'label_'+ dataset + '.mat'\n","mat = scipy.io.loadmat(label_name)\n","label_all = mat['label_all'][0]\n","classes = np.unique(label_all)\n","num_classes = classes.size\n","\n","# X_feature = my_kernel(X_feature,label_all)\n","\n","# def my_kernel(X, Y):\n","#         \"\"\"\n","#         We create a custom kernel:\n","\n","#                     (2  0)\n","#         k(X, Y) = X  (    ) Y.T\n","#                     (0  1)\n","#         \"\"\"\n","#         # print(\"X shape\",X.shape)\n","#         # print(\"Kernel shape\", kernel.shape)\n","        \n","#         # s1 = np.dot(X.T,kernel)\n","#         # print(s1.shape)\n","#         # print(\"label shape\", Y.shape)\n","#         # s2 = np.dot(s1, Y)\n","#         s2 = np.dot(X,X.T)\n","#         # print(\"return shape\",s2.shape)\n","#         return s2\n","\n","# X_feature = my_kernel(X_feature, label_all)\n","# print(\"X_feature final shape\",X_feature.shape)\n","\n","def run_gk():\n","  # visualize_with_tSNE(X_feature, label_all)\n","\n","  print('*********** dataset_name =', dataset_name,' *******************')\n","\n","  predicted_labels = []\n","  acc_all = []\n","  auc_all = []\n","  f1score_all = []\n","\n","  ##**** Logistic Regression **** #####\n","  for fold_idx in range(5):\n","      train_idx, test_idx = separate_data_idx(label_all, fold_idx)\n","      G_train = X_feature[train_idx,:]\n","      G_test = X_feature[test_idx,:]\n","      y_train = label_all[train_idx]\n","      y_test = label_all[test_idx]\n","\n","      # G_train, G_test, y_train, y_test = train_test_split(X_feature, label_all, test_size=0.1)\n","\n","      #GK transform\n","      # K_train = gk.fit_transform(G_train)\n","      # K_test = gk.transform(G_test)\n","\n","      # cls = LogisticRegression(tol=0.001, max_iter = 2000)\n","      cls = svm.SVC(kernel=kernel)\n","      print(\"training...\")\n","      cls.fit(G_train, y_train)\n","      print(\"done.\")\n","      \n","      # cls.fit(K_train, y_train)\n","      # ACC = cls.score(test_embeddings, test_labels)\n","\n","      predicted = cls.predict(G_test)\n","      print(predicted)\n","\n","      acc, auc, precision, recall, f1score = calculate_acc(predicted, y_test)\n","\n","      print(' acc ', acc, ' auc ', auc, ' precision ', precision, ' recall ', recall, ' f1score ', f1score) \n","\n","      \n","      acc_all.append(acc)\n","      auc_all.append(auc)\n","      f1score_all.append(f1score)\n","\n","      acc_all = np.array(acc_all)\n","      auc_all = np.array(auc_all)\n","      f1score_all = np.array(f1score_all)\n","\n","  # print('acc_all = ', acc_all)   \n","\n","  # print('auc_all = ', auc_all) \n","  \n","  return acc_all, auc_all, f1score_all\n","\n","total_acc = []\n","total_auc = []\n","total_f1score = []\n","iter = 1\n","for i in range(iter):\n","  # run_gk()\n","  acc_all,auc_all, f1score_all = run_gk()\n","  total_acc.append(acc_all)\n","  total_auc.append(auc_all)\n","  total_f1score.append(f1score_all)\n","\n","# print_results(total_acc, total_auc, total_f1score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tbwRmOnmh4_I"},"outputs":[],"source":["print(\"ACC:\", np.mean(total_acc))"]},{"cell_type":"markdown","metadata":{"id":"mciqHfHChq7i"},"source":["### PCA"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9067,"status":"ok","timestamp":1666067675668,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"},"user_tz":240},"id":"7dJizfIIhqPf","outputId":"158a2c54-7974-46b6-8071-508c51ae775a"},"outputs":[{"output_type":"stream","name":"stdout","text":["(80, 60)\n","*********** dataset_name = dataset_2_connectivity_matrix.mat  *******************\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  0  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    1.0000    0.9333         7\n","           1     1.0000    0.8889    0.9412         9\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  1  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","              precision    recall  f1-score   support\n","\n","           0     0.7500    1.0000    0.8571         6\n","           1     1.0000    0.8000    0.8889        10\n","\n","    accuracy                         0.8750        16\n","   macro avg     0.8750    0.9000    0.8730        16\n","weighted avg     0.9062    0.8750    0.8770        16\n","\n","fold  2  acc  0.875  auc  0.875  precision  0.9  recall  0.875  f1score  0.873015873015873\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  3  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","              precision    recall  f1-score   support\n","\n","           0     0.7500    0.8571    0.8000         7\n","           1     0.8750    0.7778    0.8235         9\n","\n","    accuracy                         0.8125        16\n","   macro avg     0.8125    0.8175    0.8118        16\n","weighted avg     0.8203    0.8125    0.8132        16\n","\n","fold  4  acc  0.8125  auc  0.8125  precision  0.8174603174603174  recall  0.8125  f1score  0.8117647058823529\n","Accuracy from all runs:  [array([0.9375, 0.9375, 0.875 , 0.9375, 0.8125])]\n","AUC from all runs:  [array([0.9375, 0.9375, 0.875 , 0.9375, 0.8125])]\n","Average acc =  0.9\n","STD =  0.05\n","Average auc =  0.9\n","STD =  0.05\n","Average f1score =  0.8993090569561157\n","STD =  0.05034879618421212\n"]}],"source":["import numpy as np\n","import scipy.io\n","import os\n","\n","os.chdir('/content/gdrive/My Drive/Graph_based_methods/Graph_Transformer/dataset/Features_Omar_new')\n","\n","# dataset = data_with_\n","# data_name = data_without_\n","# use_degree_as_tag = False\n","# dataset_name = dataset + '_RBF_plus_connectivity_manual_matrix.mat'\n","# dataset_name = dataset + '_RBF_manual_matrix.mat'\n","# dataset_name = dataset + '_label_embedding_matrix.mat'\n","# dataset_name = dataset + '_connectivity_matrix.mat'\n","\n","def run_PCA():\n","  # random.seed()\n","  mat = scipy.io.loadmat(dataset_name)\n","  X = mat['X_feature_tensor']\n","\n","  ndims_X = np.ndim(X)\n","\n","  if(ndims_X == 3):\n","    X = Matrix2Vec(X)\n","\n","  X_feature = Feature_reduction_PCA(X, 60)\n","  print(X_feature.shape)\n","  # X_feature = X\n","\n","  label_name = 'label_'+ dataset + '.mat'\n","  mat = scipy.io.loadmat(label_name)\n","  label_all = mat['label_all'][0]\n","  classes = np.unique(label_all)\n","  num_classes = classes.size\n","\n","  # visualize_with_tSNE(X_feature, label_all)\n","\n","  print('*********** dataset_name =', dataset_name,' *******************')\n","\n","  predicted_labels = []\n","  acc_all = []\n","  auc_all = []\n","  f1score_all = []\n","\n","\n","  ##**** Logistic Regression **** #####\n","  for fold_idx in range(5):\n","      train_idx, test_idx = separate_data_idx(label_all, fold_idx)\n","      train_embeddings = X_feature[train_idx,:]\n","      test_embeddings = X_feature[test_idx,:]\n","      train_labels = label_all[train_idx]\n","      test_labels = label_all[test_idx]\n","\n","      cls = LogisticRegression(tol=0.001, max_iter = 2000)\n","      cls.fit(train_embeddings, train_labels)\n","      ACC = cls.score(test_embeddings, test_labels)\n","\n","      predicted = cls.predict(test_embeddings)\n","      predicted_labels.append(predicted)\n","\n","      acc, auc, precision, recall, f1score = calculate_acc(predicted, test_labels)\n","\n","      print('fold ', fold_idx, ' acc ', ACC, ' auc ', auc, ' precision ', precision, ' recall ', recall, ' f1score ', f1score) \n","\n","      \n","      acc_all.append(acc)\n","      auc_all.append(auc)\n","      f1score_all.append(f1score)\n","\n","  acc_all = np.array(acc_all)\n","  auc_all = np.array(auc_all)\n","  f1score_all = np.array(f1score_all)\n","\n","  # print('acc_all = ', acc_all)   \n","\n","  # print('auc_all = ', auc_all) \n","  \n","  return acc_all, auc_all, f1score_all\n","\n","total_acc = []\n","total_auc = []\n","total_f1score = []\n","iter = 1\n","for i in range(iter):\n","  acc_all,auc_all, f1score_all = run_PCA()\n","  total_acc.append(acc_all)\n","  total_auc.append(auc_all)\n","  total_f1score.append(f1score_all)\n","\n","print_results(total_acc, total_auc, total_f1score)\n","##**** FCN Classify **** #####\n","# for fold_idx in range(5):\n","#     train_idx, test_idx = separate_data_idx(label_all, fold_idx)\n","#     train_embeddings = X_feature[train_idx,:]\n","#     test_embeddings = X_feature[test_idx,:]\n","#     train_labels = label_all[train_idx]\n","#     test_labels = label_all[test_idx] \n","\n","#     predicted = FCN_classify(train_embeddings, test_embeddings, train_labels, test_labels, num_classes)\n","#     predicted_labels.append(predicted)\n","\n","#     acc, auc = calculate_acc(predicted, test_labels)\n","\n","#     print('fold ', fold_idx, ' acc ', acc, ' auc ', auc) \n","\n","#     auc_all.append(auc)\n","#     acc_all.append(acc)\n","\n","# acc_all = np.array(acc_all)\n","# auc_all = np.array(auc_all)\n","\n","# print('acc_all = ', acc_all)   \n","\n","# print('auc_all = ', auc_all) \n","\n","\n","##**** Repeat FCN Classify **** #####\n","# iter = 20\n","# acc_all = []\n","# for i in range(iter):\n","#   acc_i = 0\n","#   for fold_idx in range(5):\n","#       train_idx, test_idx = separate_data_idx(label_all, fold_idx)\n","#       train_embeddings = X_feature[train_idx,:]\n","#       test_embeddings = X_feature[test_idx,:]\n","#       train_labels = label_all[train_idx]\n","#       test_labels = label_all[test_idx] \n","\n","#       predicted = FCN_classify(train_embeddings, test_embeddings, train_labels, test_labels, num_classes)\n","#       predicted_labels.append(predicted)\n","\n","#       acc, auc = calculate_acc(predicted, test_labels)\n","\n","#       # print('fold ', fold_idx, ' acc ', acc, ' auc ', auc) \n","\n","#       acc_i += acc\n","\n","#   avg_acc_i = acc_i/(fold_idx + 1) \n","#   acc_all.append(avg_acc_i)   \n","\n","\n","\n","# acc_all = np.array(acc_all)\n","# # auc_all = np.array(auc_all)\n","\n","# print('acc_all = ', acc_all)   \n","\n","# # print('auc_all = ', auc_all) "]},{"cell_type":"markdown","metadata":{"id":"pVkNYNQYojjM"},"source":["### PCA + node features\n"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85840,"status":"ok","timestamp":1666068409137,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"},"user_tz":240},"id":"8b9XhFNoonGw","outputId":"c9b17387-892e-462c-ccdd-fef1bcaf22bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading data\n","# classes: 2\n","# maximum node tag: 3\n","# data: 80\n","(80, 60)\n","(80, 537)\n","(80, 597)\n","*********** dataset_name = dataset_2_connectivity_matrix.mat  *******************\n","[ 3 13 21 25 27 32 38 39 50 54 57 59 67 68 70 72]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  0  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 4  5  7 19 20 23 29 36 40 41 48 61 63 66 74 77]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         8\n","           1     1.0000    1.0000    1.0000         8\n","\n","    accuracy                         1.0000        16\n","   macro avg     1.0000    1.0000    1.0000        16\n","weighted avg     1.0000    1.0000    1.0000        16\n","\n","fold  1  acc  1.0  auc  1.0  precision  1.0  recall  1.0  f1score  1.0\n","[ 0  1  8 17 22 33 34 35 45 46 55 58 64 65 69 76]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    1.0000    0.9333         7\n","           1     1.0000    0.8889    0.9412         9\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  2  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 2  6  9 10 15 28 30 31 42 44 52 53 56 62 73 78]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  3  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[11 12 14 16 18 24 26 37 43 47 49 51 60 71 75 79]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    0.8750    0.8750         8\n","           1     0.8750    0.8750    0.8750         8\n","\n","    accuracy                         0.8750        16\n","   macro avg     0.8750    0.8750    0.8750        16\n","weighted avg     0.8750    0.8750    0.8750        16\n","\n","fold  4  acc  0.875  auc  0.875  precision  0.875  recall  0.875  f1score  0.875\n","loading data\n","# classes: 2\n","# maximum node tag: 3\n","# data: 80\n","(80, 60)\n","(80, 537)\n","(80, 597)\n","*********** dataset_name = dataset_2_connectivity_matrix.mat  *******************\n","[ 3 13 21 25 27 32 38 39 50 54 57 59 67 68 70 72]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  0  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 4  5  7 19 20 23 29 36 40 41 48 61 63 66 74 77]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         8\n","           1     1.0000    1.0000    1.0000         8\n","\n","    accuracy                         1.0000        16\n","   macro avg     1.0000    1.0000    1.0000        16\n","weighted avg     1.0000    1.0000    1.0000        16\n","\n","fold  1  acc  1.0  auc  1.0  precision  1.0  recall  1.0  f1score  1.0\n","[ 0  1  8 17 22 33 34 35 45 46 55 58 64 65 69 76]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    1.0000    0.9333         7\n","           1     1.0000    0.8889    0.9412         9\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  2  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 2  6  9 10 15 28 30 31 42 44 52 53 56 62 73 78]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  3  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[11 12 14 16 18 24 26 37 43 47 49 51 60 71 75 79]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    0.8750    0.8750         8\n","           1     0.8750    0.8750    0.8750         8\n","\n","    accuracy                         0.8750        16\n","   macro avg     0.8750    0.8750    0.8750        16\n","weighted avg     0.8750    0.8750    0.8750        16\n","\n","fold  4  acc  0.875  auc  0.875  precision  0.875  recall  0.875  f1score  0.875\n","loading data\n","# classes: 2\n","# maximum node tag: 3\n","# data: 80\n","(80, 60)\n","(80, 537)\n","(80, 597)\n","*********** dataset_name = dataset_2_connectivity_matrix.mat  *******************\n","[ 3 13 21 25 27 32 38 39 50 54 57 59 67 68 70 72]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  0  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 4  5  7 19 20 23 29 36 40 41 48 61 63 66 74 77]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         8\n","           1     1.0000    1.0000    1.0000         8\n","\n","    accuracy                         1.0000        16\n","   macro avg     1.0000    1.0000    1.0000        16\n","weighted avg     1.0000    1.0000    1.0000        16\n","\n","fold  1  acc  1.0  auc  1.0  precision  1.0  recall  1.0  f1score  1.0\n","[ 0  1  8 17 22 33 34 35 45 46 55 58 64 65 69 76]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    1.0000    0.9333         7\n","           1     1.0000    0.8889    0.9412         9\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  2  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 2  6  9 10 15 28 30 31 42 44 52 53 56 62 73 78]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  3  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[11 12 14 16 18 24 26 37 43 47 49 51 60 71 75 79]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    0.8750    0.8750         8\n","           1     0.8750    0.8750    0.8750         8\n","\n","    accuracy                         0.8750        16\n","   macro avg     0.8750    0.8750    0.8750        16\n","weighted avg     0.8750    0.8750    0.8750        16\n","\n","fold  4  acc  0.875  auc  0.875  precision  0.875  recall  0.875  f1score  0.875\n","loading data\n","# classes: 2\n","# maximum node tag: 3\n","# data: 80\n","(80, 60)\n","(80, 537)\n","(80, 597)\n","*********** dataset_name = dataset_2_connectivity_matrix.mat  *******************\n","[ 3 13 21 25 27 32 38 39 50 54 57 59 67 68 70 72]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  0  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 4  5  7 19 20 23 29 36 40 41 48 61 63 66 74 77]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         8\n","           1     1.0000    1.0000    1.0000         8\n","\n","    accuracy                         1.0000        16\n","   macro avg     1.0000    1.0000    1.0000        16\n","weighted avg     1.0000    1.0000    1.0000        16\n","\n","fold  1  acc  1.0  auc  1.0  precision  1.0  recall  1.0  f1score  1.0\n","[ 0  1  8 17 22 33 34 35 45 46 55 58 64 65 69 76]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    1.0000    0.9333         7\n","           1     1.0000    0.8889    0.9412         9\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  2  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 2  6  9 10 15 28 30 31 42 44 52 53 56 62 73 78]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  3  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[11 12 14 16 18 24 26 37 43 47 49 51 60 71 75 79]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    0.8750    0.8750         8\n","           1     0.8750    0.8750    0.8750         8\n","\n","    accuracy                         0.8750        16\n","   macro avg     0.8750    0.8750    0.8750        16\n","weighted avg     0.8750    0.8750    0.8750        16\n","\n","fold  4  acc  0.875  auc  0.875  precision  0.875  recall  0.875  f1score  0.875\n","loading data\n","# classes: 2\n","# maximum node tag: 3\n","# data: 80\n","(80, 60)\n","(80, 537)\n","(80, 597)\n","*********** dataset_name = dataset_2_connectivity_matrix.mat  *******************\n","[ 3 13 21 25 27 32 38 39 50 54 57 59 67 68 70 72]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  0  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 4  5  7 19 20 23 29 36 40 41 48 61 63 66 74 77]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         8\n","           1     1.0000    1.0000    1.0000         8\n","\n","    accuracy                         1.0000        16\n","   macro avg     1.0000    1.0000    1.0000        16\n","weighted avg     1.0000    1.0000    1.0000        16\n","\n","fold  1  acc  1.0  auc  1.0  precision  1.0  recall  1.0  f1score  1.0\n","[ 0  1  8 17 22 33 34 35 45 46 55 58 64 65 69 76]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    1.0000    0.9333         7\n","           1     1.0000    0.8889    0.9412         9\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  2  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 2  6  9 10 15 28 30 31 42 44 52 53 56 62 73 78]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  3  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[11 12 14 16 18 24 26 37 43 47 49 51 60 71 75 79]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    0.8750    0.8750         8\n","           1     0.8750    0.8750    0.8750         8\n","\n","    accuracy                         0.8750        16\n","   macro avg     0.8750    0.8750    0.8750        16\n","weighted avg     0.8750    0.8750    0.8750        16\n","\n","fold  4  acc  0.875  auc  0.875  precision  0.875  recall  0.875  f1score  0.875\n","loading data\n","# classes: 2\n","# maximum node tag: 3\n","# data: 80\n","(80, 60)\n","(80, 537)\n","(80, 597)\n","*********** dataset_name = dataset_2_connectivity_matrix.mat  *******************\n","[ 3 13 21 25 27 32 38 39 50 54 57 59 67 68 70 72]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  0  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 4  5  7 19 20 23 29 36 40 41 48 61 63 66 74 77]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         8\n","           1     1.0000    1.0000    1.0000         8\n","\n","    accuracy                         1.0000        16\n","   macro avg     1.0000    1.0000    1.0000        16\n","weighted avg     1.0000    1.0000    1.0000        16\n","\n","fold  1  acc  1.0  auc  1.0  precision  1.0  recall  1.0  f1score  1.0\n","[ 0  1  8 17 22 33 34 35 45 46 55 58 64 65 69 76]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    1.0000    0.9333         7\n","           1     1.0000    0.8889    0.9412         9\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  2  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 2  6  9 10 15 28 30 31 42 44 52 53 56 62 73 78]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  3  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[11 12 14 16 18 24 26 37 43 47 49 51 60 71 75 79]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    0.8750    0.8750         8\n","           1     0.8750    0.8750    0.8750         8\n","\n","    accuracy                         0.8750        16\n","   macro avg     0.8750    0.8750    0.8750        16\n","weighted avg     0.8750    0.8750    0.8750        16\n","\n","fold  4  acc  0.875  auc  0.875  precision  0.875  recall  0.875  f1score  0.875\n","loading data\n","# classes: 2\n","# maximum node tag: 3\n","# data: 80\n","(80, 60)\n","(80, 537)\n","(80, 597)\n","*********** dataset_name = dataset_2_connectivity_matrix.mat  *******************\n","[ 3 13 21 25 27 32 38 39 50 54 57 59 67 68 70 72]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  0  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 4  5  7 19 20 23 29 36 40 41 48 61 63 66 74 77]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         8\n","           1     1.0000    1.0000    1.0000         8\n","\n","    accuracy                         1.0000        16\n","   macro avg     1.0000    1.0000    1.0000        16\n","weighted avg     1.0000    1.0000    1.0000        16\n","\n","fold  1  acc  1.0  auc  1.0  precision  1.0  recall  1.0  f1score  1.0\n","[ 0  1  8 17 22 33 34 35 45 46 55 58 64 65 69 76]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    1.0000    0.9333         7\n","           1     1.0000    0.8889    0.9412         9\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  2  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 2  6  9 10 15 28 30 31 42 44 52 53 56 62 73 78]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  3  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[11 12 14 16 18 24 26 37 43 47 49 51 60 71 75 79]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    0.8750    0.8750         8\n","           1     0.8750    0.8750    0.8750         8\n","\n","    accuracy                         0.8750        16\n","   macro avg     0.8750    0.8750    0.8750        16\n","weighted avg     0.8750    0.8750    0.8750        16\n","\n","fold  4  acc  0.875  auc  0.875  precision  0.875  recall  0.875  f1score  0.875\n","loading data\n","# classes: 2\n","# maximum node tag: 3\n","# data: 80\n","(80, 60)\n","(80, 537)\n","(80, 597)\n","*********** dataset_name = dataset_2_connectivity_matrix.mat  *******************\n","[ 3 13 21 25 27 32 38 39 50 54 57 59 67 68 70 72]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  0  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 4  5  7 19 20 23 29 36 40 41 48 61 63 66 74 77]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         8\n","           1     1.0000    1.0000    1.0000         8\n","\n","    accuracy                         1.0000        16\n","   macro avg     1.0000    1.0000    1.0000        16\n","weighted avg     1.0000    1.0000    1.0000        16\n","\n","fold  1  acc  1.0  auc  1.0  precision  1.0  recall  1.0  f1score  1.0\n","[ 0  1  8 17 22 33 34 35 45 46 55 58 64 65 69 76]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    1.0000    0.9333         7\n","           1     1.0000    0.8889    0.9412         9\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  2  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 2  6  9 10 15 28 30 31 42 44 52 53 56 62 73 78]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  3  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[11 12 14 16 18 24 26 37 43 47 49 51 60 71 75 79]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    0.8750    0.8750         8\n","           1     0.8750    0.8750    0.8750         8\n","\n","    accuracy                         0.8750        16\n","   macro avg     0.8750    0.8750    0.8750        16\n","weighted avg     0.8750    0.8750    0.8750        16\n","\n","fold  4  acc  0.875  auc  0.875  precision  0.875  recall  0.875  f1score  0.875\n","loading data\n","# classes: 2\n","# maximum node tag: 3\n","# data: 80\n","(80, 60)\n","(80, 537)\n","(80, 597)\n","*********** dataset_name = dataset_2_connectivity_matrix.mat  *******************\n","[ 3 13 21 25 27 32 38 39 50 54 57 59 67 68 70 72]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  0  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 4  5  7 19 20 23 29 36 40 41 48 61 63 66 74 77]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         8\n","           1     1.0000    1.0000    1.0000         8\n","\n","    accuracy                         1.0000        16\n","   macro avg     1.0000    1.0000    1.0000        16\n","weighted avg     1.0000    1.0000    1.0000        16\n","\n","fold  1  acc  1.0  auc  1.0  precision  1.0  recall  1.0  f1score  1.0\n","[ 0  1  8 17 22 33 34 35 45 46 55 58 64 65 69 76]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    1.0000    0.9333         7\n","           1     1.0000    0.8889    0.9412         9\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  2  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 2  6  9 10 15 28 30 31 42 44 52 53 56 62 73 78]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  3  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[11 12 14 16 18 24 26 37 43 47 49 51 60 71 75 79]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    0.8750    0.8750         8\n","           1     0.8750    0.8750    0.8750         8\n","\n","    accuracy                         0.8750        16\n","   macro avg     0.8750    0.8750    0.8750        16\n","weighted avg     0.8750    0.8750    0.8750        16\n","\n","fold  4  acc  0.875  auc  0.875  precision  0.875  recall  0.875  f1score  0.875\n","loading data\n","# classes: 2\n","# maximum node tag: 3\n","# data: 80\n","(80, 60)\n","(80, 537)\n","(80, 597)\n","*********** dataset_name = dataset_2_connectivity_matrix.mat  *******************\n","[ 3 13 21 25 27 32 38 39 50 54 57 59 67 68 70 72]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  0  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 4  5  7 19 20 23 29 36 40 41 48 61 63 66 74 77]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         8\n","           1     1.0000    1.0000    1.0000         8\n","\n","    accuracy                         1.0000        16\n","   macro avg     1.0000    1.0000    1.0000        16\n","weighted avg     1.0000    1.0000    1.0000        16\n","\n","fold  1  acc  1.0  auc  1.0  precision  1.0  recall  1.0  f1score  1.0\n","[ 0  1  8 17 22 33 34 35 45 46 55 58 64 65 69 76]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    1.0000    0.9333         7\n","           1     1.0000    0.8889    0.9412         9\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  2  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[ 2  6  9 10 15 28 30 31 42 44 52 53 56 62 73 78]\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8889    0.9412         9\n","           1     0.8750    1.0000    0.9333         7\n","\n","    accuracy                         0.9375        16\n","   macro avg     0.9375    0.9444    0.9373        16\n","weighted avg     0.9453    0.9375    0.9377        16\n","\n","fold  3  acc  0.9375  auc  0.9375  precision  0.9444444444444444  recall  0.9375  f1score  0.9372549019607843\n","[11 12 14 16 18 24 26 37 43 47 49 51 60 71 75 79]\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    0.8750    0.8750         8\n","           1     0.8750    0.8750    0.8750         8\n","\n","    accuracy                         0.8750        16\n","   macro avg     0.8750    0.8750    0.8750        16\n","weighted avg     0.8750    0.8750    0.8750        16\n","\n","fold  4  acc  0.875  auc  0.875  precision  0.875  recall  0.875  f1score  0.875\n","Accuracy from all runs:  [array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ])]\n","AUC from all runs:  [array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ]), array([0.9375, 1.    , 0.9375, 0.9375, 0.875 ])]\n","Average acc =  0.9375\n","STD =  0.03952847075210474\n","Average auc =  0.9375\n","STD =  0.03952847075210474\n","Average f1score =  0.9373529411764707\n","STD =  0.03952865312063792\n"]}],"source":["import numpy as np\n","import scipy.io\n","import os\n","\n","# dataset = data_with_\n","# data_name = data_without_\n","# use_degree_as_tag = False\n","# dataset_name = dataset + '_RBF_plus_connectivity_manual_matrix.mat'\n","# dataset_name = dataset + '_RBF_manual_matrix.mat'\n","# dataset_name = dataset + '_label_embedding_matrix.mat'\n","# dataset_name = dataset + '_connectivity_matrix.mat'\n","\n","def run_PCA_NF():\n","  mat = scipy.io.loadmat(dataset_name)\n","  X = mat['X_feature_tensor']\n","\n","  ndims_X = np.ndim(X)\n","\n","  if(ndims_X == 3):\n","    X = Matrix2Vec(X)\n","\n","  X_feature = Feature_reduction_PCA(X, 60)\n","  X_node_feature = load_and_process_node_features(data_name, use_degree_as_tag)\n","\n","  print(X_feature.shape)\n","  print(X_node_feature.shape)\n","\n","  X_feature = np.concatenate((X_feature, X_node_feature), axis = 1)\n","\n","  print(X_feature.shape)\n","\n","  label_name = 'label_'+ dataset + '.mat'\n","  mat = scipy.io.loadmat(label_name)\n","  label_all = mat['label_all'][0]\n","  classes = np.unique(label_all)\n","  num_classes = classes.size\n","\n","  # visualize_with_tSNE(X_feature, label_all)\n","\n","  print('*********** dataset_name =', dataset_name,' *******************')\n","\n","  predicted_labels = []\n","  acc_all = []\n","  auc_all = []\n","  f1score_all = []\n","\n","\n","  ##**** Logistic Regression **** #####\n","  for fold_idx in range(5):\n","      train_idx, test_idx = separate_data_idx(label_all, fold_idx)\n","      print(test_idx)\n","      train_embeddings = X_feature[train_idx,:]\n","      test_embeddings = X_feature[test_idx,:]\n","      train_labels = label_all[train_idx]\n","      test_labels = label_all[test_idx]\n","\n","      cls = LogisticRegression(tol=0.001, max_iter = 2000)\n","      cls.fit(train_embeddings, train_labels)\n","      ACC = cls.score(test_embeddings, test_labels)\n","\n","      predicted = cls.predict(test_embeddings)\n","      predicted_labels.append(predicted)\n","\n","      acc, auc, precision, recall, f1score = calculate_acc(predicted, test_labels)\n","\n","      print('fold ', fold_idx, ' acc ', ACC, ' auc ', auc, ' precision ', precision, ' recall ', recall, ' f1score ', f1score) \n","\n","      \n","      acc_all.append(acc)\n","      auc_all.append(auc)\n","      f1score_all.append(f1score)\n","\n","  acc_all = np.array(acc_all)\n","  auc_all = np.array(auc_all)\n","\n","  # print('acc_all = ', acc_all)   \n","\n","  # print('auc_all = ', auc_all) \n","  return acc_all, auc_all, f1score_all\n","\n","\n","total_acc = []\n","total_auc = []\n","total_f1score = []\n","iter = 10\n","for i in range(iter):\n","  acc_all, auc_all, f1score_all = run_PCA_NF()\n","  total_acc.append(acc_all)\n","  total_auc.append(auc_all)\n","  total_f1score.append(f1score_all)\n","\n","print_results(total_acc, total_auc, total_f1score)"]},{"cell_type":"markdown","metadata":{"id":"nAQPJZaAVQbr"},"source":["### 2DPCA"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13229,"status":"ok","timestamp":1666067550768,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"},"user_tz":240},"id":"e3DZaM0JcuNZ","outputId":"8674eee9-d52c-4ee9-be19-2b7ea77f7412"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** dataset_name = dataset_5_connectivity_matrix.mat  *******************\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.8000    0.6667    0.7273         6\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  0  acc  0.7  auc  0.7000000000000001  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.6667    0.7273         6\n","           1     0.6000    0.7500    0.6667         4\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  1  acc  0.7  auc  0.7000000000000002  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.7500    0.6000    0.6667         5\n","\n","    accuracy                         0.6667         9\n","   macro avg     0.6750    0.6750    0.6667         9\n","weighted avg     0.6833    0.6667    0.6667         9\n","\n","fold  2  acc  0.6666666666666666  auc  0.675  precision  0.675  recall  0.675  f1score  0.6666666666666665\n","              precision    recall  f1-score   support\n","\n","           0     0.2000    0.5000    0.2857         2\n","           1     0.7500    0.4286    0.5455         7\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4750    0.4643    0.4156         9\n","weighted avg     0.6278    0.4444    0.4877         9\n","\n","fold  3  acc  0.4444444444444444  auc  0.475  precision  0.4642857142857143  recall  0.475  f1score  0.4155844155844156\n","              precision    recall  f1-score   support\n","\n","           0     0.5000    0.4000    0.4444         5\n","           1     0.4000    0.5000    0.4444         4\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4500    0.4500    0.4444         9\n","weighted avg     0.4556    0.4444    0.4444         9\n","\n","fold  4  acc  0.4444444444444444  auc  0.44999999999999996  precision  0.45  recall  0.45  f1score  0.4444444444444445\n","*********** dataset_name = dataset_5_connectivity_matrix.mat  *******************\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.8000    0.6667    0.7273         6\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  0  acc  0.7  auc  0.7000000000000001  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.6667    0.7273         6\n","           1     0.6000    0.7500    0.6667         4\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  1  acc  0.7  auc  0.7000000000000002  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.7500    0.6000    0.6667         5\n","\n","    accuracy                         0.6667         9\n","   macro avg     0.6750    0.6750    0.6667         9\n","weighted avg     0.6833    0.6667    0.6667         9\n","\n","fold  2  acc  0.6666666666666666  auc  0.675  precision  0.675  recall  0.675  f1score  0.6666666666666665\n","              precision    recall  f1-score   support\n","\n","           0     0.2000    0.5000    0.2857         2\n","           1     0.7500    0.4286    0.5455         7\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4750    0.4643    0.4156         9\n","weighted avg     0.6278    0.4444    0.4877         9\n","\n","fold  3  acc  0.4444444444444444  auc  0.475  precision  0.4642857142857143  recall  0.475  f1score  0.4155844155844156\n","              precision    recall  f1-score   support\n","\n","           0     0.5000    0.4000    0.4444         5\n","           1     0.4000    0.5000    0.4444         4\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4500    0.4500    0.4444         9\n","weighted avg     0.4556    0.4444    0.4444         9\n","\n","fold  4  acc  0.4444444444444444  auc  0.44999999999999996  precision  0.45  recall  0.45  f1score  0.4444444444444445\n","*********** dataset_name = dataset_5_connectivity_matrix.mat  *******************\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.8000    0.6667    0.7273         6\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  0  acc  0.7  auc  0.7000000000000001  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.6667    0.7273         6\n","           1     0.6000    0.7500    0.6667         4\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  1  acc  0.7  auc  0.7000000000000002  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.7500    0.6000    0.6667         5\n","\n","    accuracy                         0.6667         9\n","   macro avg     0.6750    0.6750    0.6667         9\n","weighted avg     0.6833    0.6667    0.6667         9\n","\n","fold  2  acc  0.6666666666666666  auc  0.675  precision  0.675  recall  0.675  f1score  0.6666666666666665\n","              precision    recall  f1-score   support\n","\n","           0     0.2000    0.5000    0.2857         2\n","           1     0.7500    0.4286    0.5455         7\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4750    0.4643    0.4156         9\n","weighted avg     0.6278    0.4444    0.4877         9\n","\n","fold  3  acc  0.4444444444444444  auc  0.475  precision  0.4642857142857143  recall  0.475  f1score  0.4155844155844156\n","              precision    recall  f1-score   support\n","\n","           0     0.5000    0.4000    0.4444         5\n","           1     0.4000    0.5000    0.4444         4\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4500    0.4500    0.4444         9\n","weighted avg     0.4556    0.4444    0.4444         9\n","\n","fold  4  acc  0.4444444444444444  auc  0.44999999999999996  precision  0.45  recall  0.45  f1score  0.4444444444444445\n","*********** dataset_name = dataset_5_connectivity_matrix.mat  *******************\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.8000    0.6667    0.7273         6\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  0  acc  0.7  auc  0.7000000000000001  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.6667    0.7273         6\n","           1     0.6000    0.7500    0.6667         4\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  1  acc  0.7  auc  0.7000000000000002  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.7500    0.6000    0.6667         5\n","\n","    accuracy                         0.6667         9\n","   macro avg     0.6750    0.6750    0.6667         9\n","weighted avg     0.6833    0.6667    0.6667         9\n","\n","fold  2  acc  0.6666666666666666  auc  0.675  precision  0.675  recall  0.675  f1score  0.6666666666666665\n","              precision    recall  f1-score   support\n","\n","           0     0.2000    0.5000    0.2857         2\n","           1     0.7500    0.4286    0.5455         7\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4750    0.4643    0.4156         9\n","weighted avg     0.6278    0.4444    0.4877         9\n","\n","fold  3  acc  0.4444444444444444  auc  0.475  precision  0.4642857142857143  recall  0.475  f1score  0.4155844155844156\n","              precision    recall  f1-score   support\n","\n","           0     0.5000    0.4000    0.4444         5\n","           1     0.4000    0.5000    0.4444         4\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4500    0.4500    0.4444         9\n","weighted avg     0.4556    0.4444    0.4444         9\n","\n","fold  4  acc  0.4444444444444444  auc  0.44999999999999996  precision  0.45  recall  0.45  f1score  0.4444444444444445\n","*********** dataset_name = dataset_5_connectivity_matrix.mat  *******************\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.8000    0.6667    0.7273         6\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  0  acc  0.7  auc  0.7000000000000001  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.6667    0.7273         6\n","           1     0.6000    0.7500    0.6667         4\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  1  acc  0.7  auc  0.7000000000000002  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.7500    0.6000    0.6667         5\n","\n","    accuracy                         0.6667         9\n","   macro avg     0.6750    0.6750    0.6667         9\n","weighted avg     0.6833    0.6667    0.6667         9\n","\n","fold  2  acc  0.6666666666666666  auc  0.675  precision  0.675  recall  0.675  f1score  0.6666666666666665\n","              precision    recall  f1-score   support\n","\n","           0     0.2000    0.5000    0.2857         2\n","           1     0.7500    0.4286    0.5455         7\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4750    0.4643    0.4156         9\n","weighted avg     0.6278    0.4444    0.4877         9\n","\n","fold  3  acc  0.4444444444444444  auc  0.475  precision  0.4642857142857143  recall  0.475  f1score  0.4155844155844156\n","              precision    recall  f1-score   support\n","\n","           0     0.5000    0.4000    0.4444         5\n","           1     0.4000    0.5000    0.4444         4\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4500    0.4500    0.4444         9\n","weighted avg     0.4556    0.4444    0.4444         9\n","\n","fold  4  acc  0.4444444444444444  auc  0.44999999999999996  precision  0.45  recall  0.45  f1score  0.4444444444444445\n","*********** dataset_name = dataset_5_connectivity_matrix.mat  *******************\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.8000    0.6667    0.7273         6\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  0  acc  0.7  auc  0.7000000000000001  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.6667    0.7273         6\n","           1     0.6000    0.7500    0.6667         4\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  1  acc  0.7  auc  0.7000000000000002  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.7500    0.6000    0.6667         5\n","\n","    accuracy                         0.6667         9\n","   macro avg     0.6750    0.6750    0.6667         9\n","weighted avg     0.6833    0.6667    0.6667         9\n","\n","fold  2  acc  0.6666666666666666  auc  0.675  precision  0.675  recall  0.675  f1score  0.6666666666666665\n","              precision    recall  f1-score   support\n","\n","           0     0.2000    0.5000    0.2857         2\n","           1     0.7500    0.4286    0.5455         7\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4750    0.4643    0.4156         9\n","weighted avg     0.6278    0.4444    0.4877         9\n","\n","fold  3  acc  0.4444444444444444  auc  0.475  precision  0.4642857142857143  recall  0.475  f1score  0.4155844155844156\n","              precision    recall  f1-score   support\n","\n","           0     0.5000    0.4000    0.4444         5\n","           1     0.4000    0.5000    0.4444         4\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4500    0.4500    0.4444         9\n","weighted avg     0.4556    0.4444    0.4444         9\n","\n","fold  4  acc  0.4444444444444444  auc  0.44999999999999996  precision  0.45  recall  0.45  f1score  0.4444444444444445\n","*********** dataset_name = dataset_5_connectivity_matrix.mat  *******************\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.8000    0.6667    0.7273         6\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  0  acc  0.7  auc  0.7000000000000001  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.6667    0.7273         6\n","           1     0.6000    0.7500    0.6667         4\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  1  acc  0.7  auc  0.7000000000000002  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.7500    0.6000    0.6667         5\n","\n","    accuracy                         0.6667         9\n","   macro avg     0.6750    0.6750    0.6667         9\n","weighted avg     0.6833    0.6667    0.6667         9\n","\n","fold  2  acc  0.6666666666666666  auc  0.675  precision  0.675  recall  0.675  f1score  0.6666666666666665\n","              precision    recall  f1-score   support\n","\n","           0     0.2000    0.5000    0.2857         2\n","           1     0.7500    0.4286    0.5455         7\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4750    0.4643    0.4156         9\n","weighted avg     0.6278    0.4444    0.4877         9\n","\n","fold  3  acc  0.4444444444444444  auc  0.475  precision  0.4642857142857143  recall  0.475  f1score  0.4155844155844156\n","              precision    recall  f1-score   support\n","\n","           0     0.5000    0.4000    0.4444         5\n","           1     0.4000    0.5000    0.4444         4\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4500    0.4500    0.4444         9\n","weighted avg     0.4556    0.4444    0.4444         9\n","\n","fold  4  acc  0.4444444444444444  auc  0.44999999999999996  precision  0.45  recall  0.45  f1score  0.4444444444444445\n","*********** dataset_name = dataset_5_connectivity_matrix.mat  *******************\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.8000    0.6667    0.7273         6\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  0  acc  0.7  auc  0.7000000000000001  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.6667    0.7273         6\n","           1     0.6000    0.7500    0.6667         4\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  1  acc  0.7  auc  0.7000000000000002  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.7500    0.6000    0.6667         5\n","\n","    accuracy                         0.6667         9\n","   macro avg     0.6750    0.6750    0.6667         9\n","weighted avg     0.6833    0.6667    0.6667         9\n","\n","fold  2  acc  0.6666666666666666  auc  0.675  precision  0.675  recall  0.675  f1score  0.6666666666666665\n","              precision    recall  f1-score   support\n","\n","           0     0.2000    0.5000    0.2857         2\n","           1     0.7500    0.4286    0.5455         7\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4750    0.4643    0.4156         9\n","weighted avg     0.6278    0.4444    0.4877         9\n","\n","fold  3  acc  0.4444444444444444  auc  0.475  precision  0.4642857142857143  recall  0.475  f1score  0.4155844155844156\n","              precision    recall  f1-score   support\n","\n","           0     0.5000    0.4000    0.4444         5\n","           1     0.4000    0.5000    0.4444         4\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4500    0.4500    0.4444         9\n","weighted avg     0.4556    0.4444    0.4444         9\n","\n","fold  4  acc  0.4444444444444444  auc  0.44999999999999996  precision  0.45  recall  0.45  f1score  0.4444444444444445\n","*********** dataset_name = dataset_5_connectivity_matrix.mat  *******************\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.8000    0.6667    0.7273         6\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  0  acc  0.7  auc  0.7000000000000001  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.6667    0.7273         6\n","           1     0.6000    0.7500    0.6667         4\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  1  acc  0.7  auc  0.7000000000000002  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.7500    0.6000    0.6667         5\n","\n","    accuracy                         0.6667         9\n","   macro avg     0.6750    0.6750    0.6667         9\n","weighted avg     0.6833    0.6667    0.6667         9\n","\n","fold  2  acc  0.6666666666666666  auc  0.675  precision  0.675  recall  0.675  f1score  0.6666666666666665\n","              precision    recall  f1-score   support\n","\n","           0     0.2000    0.5000    0.2857         2\n","           1     0.7500    0.4286    0.5455         7\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4750    0.4643    0.4156         9\n","weighted avg     0.6278    0.4444    0.4877         9\n","\n","fold  3  acc  0.4444444444444444  auc  0.475  precision  0.4642857142857143  recall  0.475  f1score  0.4155844155844156\n","              precision    recall  f1-score   support\n","\n","           0     0.5000    0.4000    0.4444         5\n","           1     0.4000    0.5000    0.4444         4\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4500    0.4500    0.4444         9\n","weighted avg     0.4556    0.4444    0.4444         9\n","\n","fold  4  acc  0.4444444444444444  auc  0.44999999999999996  precision  0.45  recall  0.45  f1score  0.4444444444444445\n","*********** dataset_name = dataset_5_connectivity_matrix.mat  *******************\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.8000    0.6667    0.7273         6\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  0  acc  0.7  auc  0.7000000000000001  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.6667    0.7273         6\n","           1     0.6000    0.7500    0.6667         4\n","\n","    accuracy                         0.7000        10\n","   macro avg     0.7000    0.7083    0.6970        10\n","weighted avg     0.7200    0.7000    0.7030        10\n","\n","fold  1  acc  0.7  auc  0.7000000000000002  precision  0.7083333333333333  recall  0.7  f1score  0.6969696969696968\n","              precision    recall  f1-score   support\n","\n","           0     0.6000    0.7500    0.6667         4\n","           1     0.7500    0.6000    0.6667         5\n","\n","    accuracy                         0.6667         9\n","   macro avg     0.6750    0.6750    0.6667         9\n","weighted avg     0.6833    0.6667    0.6667         9\n","\n","fold  2  acc  0.6666666666666666  auc  0.675  precision  0.675  recall  0.675  f1score  0.6666666666666665\n","              precision    recall  f1-score   support\n","\n","           0     0.2000    0.5000    0.2857         2\n","           1     0.7500    0.4286    0.5455         7\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4750    0.4643    0.4156         9\n","weighted avg     0.6278    0.4444    0.4877         9\n","\n","fold  3  acc  0.4444444444444444  auc  0.475  precision  0.4642857142857143  recall  0.475  f1score  0.4155844155844156\n","              precision    recall  f1-score   support\n","\n","           0     0.5000    0.4000    0.4444         5\n","           1     0.4000    0.5000    0.4444         4\n","\n","    accuracy                         0.4444         9\n","   macro avg     0.4500    0.4500    0.4444         9\n","weighted avg     0.4556    0.4444    0.4444         9\n","\n","fold  4  acc  0.4444444444444444  auc  0.44999999999999996  precision  0.45  recall  0.45  f1score  0.4444444444444445\n","Accuracy from all runs:  [array([0.7       , 0.7       , 0.66666667, 0.44444444, 0.44444444]), array([0.7       , 0.7       , 0.66666667, 0.44444444, 0.44444444]), array([0.7       , 0.7       , 0.66666667, 0.44444444, 0.44444444]), array([0.7       , 0.7       , 0.66666667, 0.44444444, 0.44444444]), array([0.7       , 0.7       , 0.66666667, 0.44444444, 0.44444444]), array([0.7       , 0.7       , 0.66666667, 0.44444444, 0.44444444]), array([0.7       , 0.7       , 0.66666667, 0.44444444, 0.44444444]), array([0.7       , 0.7       , 0.66666667, 0.44444444, 0.44444444]), array([0.7       , 0.7       , 0.66666667, 0.44444444, 0.44444444]), array([0.7       , 0.7       , 0.66666667, 0.44444444, 0.44444444])]\n","AUC from all runs:  [array([0.7  , 0.7  , 0.675, 0.475, 0.45 ]), array([0.7  , 0.7  , 0.675, 0.475, 0.45 ]), array([0.7  , 0.7  , 0.675, 0.475, 0.45 ]), array([0.7  , 0.7  , 0.675, 0.475, 0.45 ]), array([0.7  , 0.7  , 0.675, 0.475, 0.45 ]), array([0.7  , 0.7  , 0.675, 0.475, 0.45 ]), array([0.7  , 0.7  , 0.675, 0.475, 0.45 ]), array([0.7  , 0.7  , 0.675, 0.475, 0.45 ]), array([0.7  , 0.7  , 0.675, 0.475, 0.45 ]), array([0.7  , 0.7  , 0.675, 0.475, 0.45 ])]\n","Average acc =  0.5911111111111108\n","STD =  0.12036980056845192\n","Average auc =  0.6\n","STD =  0.11291589790636221\n","Average f1score =  0.5841269841269838\n","STD =  0.12664719829530224\n"]}],"source":["import numpy as np\n","import scipy.io\n","import os\n","\n","# os.chdir('/content/gdrive/My Drive/Graph_based_methods/Graph_Transformer/dataset/Features_Omar_new')\n","\n","# dataset = data_with_\n","# dataset_name = dataset + '_RBF_plus_connectivity_manual_matrix.mat'\n","# dataset_name = dataset + '_RBF_manual_matrix.mat'\n","# dataset_name = dataset + '_connectivity_matrix.mat'\n","\n","def run_2DPCA():\n","  mat = scipy.io.loadmat(dataset_name)\n","  X = mat['X_feature_tensor']\n","\n","  ndims_X = np.ndim(X)\n","  if(ndims_X == 2):\n","    # X = Matrix2Vec(X)\n","    X_feature = Vec2Matrix(X)\n","  X_feature = X;\n","\n","  X_feature_r = Feature_reduction_2DPCA(X_feature, 60)\n","\n","  X_feature = Matrix2Vec(X_feature_r)\n","\n","  label_name = 'label_'+ dataset + '.mat'\n","  mat = scipy.io.loadmat(label_name)\n","  label_all = mat['label_all'][0]\n","  classes = np.unique(label_all)\n","  num_classes = classes.size\n","\n","  print('*********** dataset_name =', dataset_name,' *******************')\n","\n","\n","  #### Logistic Regression #####\n","  predicted_labels = []\n","  acc_all = []\n","  auc_all = []\n","  f1score_all = []\n","\n","\n","  for fold_idx in range(5):\n","      train_idx, test_idx = separate_data_idx(label_all, fold_idx)\n","      train_embeddings = X_feature[train_idx,:]\n","      test_embeddings = X_feature[test_idx,:]\n","      train_labels = label_all[train_idx]\n","      test_labels = label_all[test_idx]\n","\n","      cls = LogisticRegression(tol=0.001, max_iter = 2000)\n","      cls.fit(train_embeddings, train_labels)\n","      ACC = cls.score(test_embeddings, test_labels)\n","\n","      predicted = cls.predict(test_embeddings)\n","      predicted_labels.append(predicted)\n","\n","      acc, auc, precision, recall, f1score = calculate_acc(predicted, test_labels)\n","\n","      print('fold ', fold_idx, ' acc ', ACC, ' auc ', auc, ' precision ', precision, ' recall ', recall, ' f1score ', f1score) \n","\n","      auc_all.append(auc)\n","      acc_all.append(acc)\n","      f1score_all.append(f1score)\n","\n","  acc_all = np.array(acc_all)\n","  auc_all = np.array(auc_all)\n","  f1score_all = np.array(f1score_all)\n","\n","  return acc_all, auc_all, f1score_all\n","\n","total_acc = []\n","total_auc = []\n","total_f1score = []\n","iter = 10\n","for i in range(iter):\n","  acc_all,auc_all, f1score_all = run_2DPCA()\n","  total_acc.append(acc_all)\n","  total_auc.append(auc_all)\n","  total_f1score.append(f1score_all)\n","\n","print_results(total_acc, total_auc, total_f1score)\n","  # print('acc_all = ', acc_all)   \n","\n","  # print('auc_all = ', auc_all) \n","\n","##**** Repeat FCN Classify **** #####\n","# iter = 20\n","# acc_all = []\n","# for i in range(iter):\n","#   acc_i = 0\n","#   for fold_idx in range(5):\n","#       train_idx, test_idx = separate_data_idx(label_all, fold_idx)\n","#       train_embeddings = X_feature[train_idx,:]\n","#       test_embeddings = X_feature[test_idx,:]\n","#       train_labels = label_all[train_idx]\n","#       test_labels = label_all[test_idx] \n","\n","#       predicted = FCN_classify(train_embeddings, test_embeddings, train_labels, test_labels, num_classes)\n","#       predicted_labels.append(predicted)\n","\n","#       acc, auc = calculate_acc(predicted, test_labels)\n","\n","#       # print('fold ', fold_idx, ' acc ', acc, ' auc ', auc) \n","\n","#       acc_i += acc\n","\n","#   avg_acc_i = acc_i/(fold_idx + 1) \n","#   acc_all.append(avg_acc_i)   \n","\n","\n","\n","# acc_all = np.array(acc_all)\n","# # auc_all = np.array(auc_all)\n","\n","# print('acc_all = ', acc_all)   \n","\n","# print('auc_all = ', auc_all) "]},{"cell_type":"markdown","metadata":{"id":"HIjiACTl6iKP"},"source":["### CNN classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5565594,"status":"ok","timestamp":1664129609187,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"},"user_tz":240},"id":"zSECN1MG6hpe","outputId":"cfced185-974b-4300-9d69-1ec530542f4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keract in /usr/local/lib/python3.7/dist-packages (4.5.1)\n","*********** dataset_name = dataset_1_connectivity_matrix.mat  *******************\n","number of classes:  2\n","[]\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["8/8 [==============================] - 30s 4s/step - loss: 0.6906 - accuracy: 0.7292 - val_loss: 0.4784 - val_accuracy: 0.8333\n","Epoch 2/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.3765 - accuracy: 0.8542 - val_loss: 0.4286 - val_accuracy: 0.8333\n","Epoch 3/30\n","8/8 [==============================] - 21s 3s/step - loss: 0.2341 - accuracy: 0.9375 - val_loss: 0.2669 - val_accuracy: 0.8333\n","Epoch 4/30\n","8/8 [==============================] - 19s 2s/step - loss: 0.1417 - accuracy: 0.9792 - val_loss: 0.2809 - val_accuracy: 0.9167\n","Epoch 5/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0946 - accuracy: 0.9792 - val_loss: 0.2337 - val_accuracy: 0.9167\n","Epoch 6/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0658 - accuracy: 0.9792 - val_loss: 0.2993 - val_accuracy: 0.9167\n","Epoch 7/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0424 - accuracy: 0.9792 - val_loss: 0.2155 - val_accuracy: 0.9167\n","Epoch 8/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9167\n","Epoch 9/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9167\n","Epoch 10/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9167\n","Epoch 11/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9167\n","Epoch 12/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9167\n","Epoch 13/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9167\n","Epoch 14/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9167\n","Epoch 15/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9167\n","Epoch 16/30\n","8/8 [==============================] - 21s 3s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9167\n","Epoch 17/30\n","8/8 [==============================] - 19s 2s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9167\n","Epoch 18/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9167\n","Epoch 19/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9167\n","Epoch 20/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9167\n","Epoch 21/30\n","8/8 [==============================] - 18s 2s/step - loss: 9.3398e-04 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9167\n","Epoch 22/30\n","8/8 [==============================] - 18s 2s/step - loss: 8.4878e-04 - accuracy: 1.0000 - val_loss: 0.2659 - val_accuracy: 0.9167\n","Epoch 23/30\n","8/8 [==============================] - 18s 2s/step - loss: 7.6709e-04 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9167\n","Epoch 24/30\n","8/8 [==============================] - 18s 2s/step - loss: 7.1064e-04 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9167\n","Epoch 25/30\n","8/8 [==============================] - 18s 2s/step - loss: 6.4665e-04 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9167\n","Epoch 26/30\n","8/8 [==============================] - 17s 2s/step - loss: 6.0597e-04 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9167\n","Epoch 27/30\n","8/8 [==============================] - 18s 2s/step - loss: 5.5938e-04 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9167\n","Epoch 28/30\n","8/8 [==============================] - 18s 2s/step - loss: 5.2878e-04 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9167\n","Epoch 29/30\n","8/8 [==============================] - 19s 2s/step - loss: 4.9006e-04 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.9167\n","Epoch 30/30\n","8/8 [==============================] - 19s 2s/step - loss: 4.5909e-04 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9167\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8571    0.9231         7\n","           1     0.8333    1.0000    0.9091         5\n","\n","    accuracy                         0.9167        12\n","   macro avg     0.9167    0.9286    0.9161        12\n","weighted avg     0.9306    0.9167    0.9172        12\n","\n","fold  0  acc  0.9166666666666666  auc  0.9166666666666667  precision  0.9285714285714286  recall  0.9166666666666667  f1score  0.916083916083916\n","[]\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["8/8 [==============================] - 19s 2s/step - loss: 0.6862 - accuracy: 0.6250 - val_loss: 0.7009 - val_accuracy: 0.5000\n","Epoch 2/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.5181 - accuracy: 0.7500 - val_loss: 0.4525 - val_accuracy: 0.8333\n","Epoch 3/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.3403 - accuracy: 0.8542 - val_loss: 0.9644 - val_accuracy: 0.7500\n","Epoch 4/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.1725 - accuracy: 0.9792 - val_loss: 0.3570 - val_accuracy: 0.8333\n","Epoch 5/30\n","8/8 [==============================] - 19s 2s/step - loss: 0.0893 - accuracy: 0.9792 - val_loss: 0.4613 - val_accuracy: 0.8333\n","Epoch 6/30\n","8/8 [==============================] - 19s 2s/step - loss: 0.0437 - accuracy: 0.9792 - val_loss: 0.4566 - val_accuracy: 0.8333\n","Epoch 7/30\n","8/8 [==============================] - 21s 3s/step - loss: 0.0277 - accuracy: 0.9792 - val_loss: 0.5032 - val_accuracy: 0.8333\n","Epoch 8/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.5659 - val_accuracy: 0.8333\n","Epoch 9/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.5650 - val_accuracy: 0.9167\n","Epoch 10/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6261 - val_accuracy: 0.8333\n","Epoch 11/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6456 - val_accuracy: 0.8333\n","Epoch 12/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6750 - val_accuracy: 0.9167\n","Epoch 13/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8333\n","Epoch 14/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7307 - val_accuracy: 0.8333\n","Epoch 15/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7453 - val_accuracy: 0.8333\n","Epoch 16/30\n","8/8 [==============================] - 18s 2s/step - loss: 9.2417e-04 - accuracy: 1.0000 - val_loss: 0.7566 - val_accuracy: 0.8333\n","Epoch 17/30\n","8/8 [==============================] - 18s 2s/step - loss: 7.8168e-04 - accuracy: 1.0000 - val_loss: 0.7729 - val_accuracy: 0.8333\n","Epoch 18/30\n","8/8 [==============================] - 19s 2s/step - loss: 7.2413e-04 - accuracy: 1.0000 - val_loss: 0.7822 - val_accuracy: 0.8333\n","Epoch 19/30\n","8/8 [==============================] - 18s 2s/step - loss: 6.2694e-04 - accuracy: 1.0000 - val_loss: 0.7987 - val_accuracy: 0.8333\n","Epoch 20/30\n","8/8 [==============================] - 18s 2s/step - loss: 5.8312e-04 - accuracy: 1.0000 - val_loss: 0.8040 - val_accuracy: 0.8333\n","Epoch 21/30\n","8/8 [==============================] - 18s 2s/step - loss: 5.2679e-04 - accuracy: 1.0000 - val_loss: 0.8210 - val_accuracy: 0.8333\n","Epoch 22/30\n","8/8 [==============================] - 18s 2s/step - loss: 4.6686e-04 - accuracy: 1.0000 - val_loss: 0.8255 - val_accuracy: 0.8333\n","Epoch 23/30\n","8/8 [==============================] - 19s 2s/step - loss: 4.2560e-04 - accuracy: 1.0000 - val_loss: 0.8351 - val_accuracy: 0.8333\n","Epoch 24/30\n","8/8 [==============================] - 18s 2s/step - loss: 3.8273e-04 - accuracy: 1.0000 - val_loss: 0.8410 - val_accuracy: 0.8333\n","Epoch 25/30\n","8/8 [==============================] - 19s 2s/step - loss: 3.5171e-04 - accuracy: 1.0000 - val_loss: 0.8521 - val_accuracy: 0.8333\n","Epoch 26/30\n","8/8 [==============================] - 18s 2s/step - loss: 3.2555e-04 - accuracy: 1.0000 - val_loss: 0.8593 - val_accuracy: 0.8333\n","Epoch 27/30\n","8/8 [==============================] - 19s 2s/step - loss: 3.0594e-04 - accuracy: 1.0000 - val_loss: 0.8653 - val_accuracy: 0.8333\n","Epoch 28/30\n","8/8 [==============================] - 19s 2s/step - loss: 2.7871e-04 - accuracy: 1.0000 - val_loss: 0.8781 - val_accuracy: 0.8333\n","Epoch 29/30\n","8/8 [==============================] - 20s 3s/step - loss: 2.5951e-04 - accuracy: 1.0000 - val_loss: 0.8837 - val_accuracy: 0.8333\n","Epoch 30/30\n","8/8 [==============================] - 20s 3s/step - loss: 2.4428e-04 - accuracy: 1.0000 - val_loss: 0.8897 - val_accuracy: 0.8333\n","              precision    recall  f1-score   support\n","\n","           0     0.8333    0.8333    0.8333         6\n","           1     0.8333    0.8333    0.8333         6\n","\n","    accuracy                         0.8333        12\n","   macro avg     0.8333    0.8333    0.8333        12\n","weighted avg     0.8333    0.8333    0.8333        12\n","\n","fold  1  acc  0.8333333333333334  auc  0.8333333333333334  precision  0.8333333333333334  recall  0.8333333333333334  f1score  0.8333333333333334\n","[]\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["8/8 [==============================] - 22s 3s/step - loss: 0.6711 - accuracy: 0.6042 - val_loss: 0.4888 - val_accuracy: 0.7500\n","Epoch 2/30\n","8/8 [==============================] - 20s 2s/step - loss: 0.3963 - accuracy: 0.8542 - val_loss: 0.3152 - val_accuracy: 0.8333\n","Epoch 3/30\n","8/8 [==============================] - 19s 2s/step - loss: 0.2495 - accuracy: 0.9167 - val_loss: 0.5056 - val_accuracy: 0.7500\n","Epoch 4/30\n","8/8 [==============================] - 19s 2s/step - loss: 0.2024 - accuracy: 0.9583 - val_loss: 0.2128 - val_accuracy: 0.8333\n","Epoch 5/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.1624 - accuracy: 0.9167 - val_loss: 0.4074 - val_accuracy: 0.8333\n","Epoch 6/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.1102 - accuracy: 0.9792 - val_loss: 0.1905 - val_accuracy: 0.9167\n","Epoch 7/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0819 - accuracy: 0.9792 - val_loss: 0.1608 - val_accuracy: 1.0000\n","Epoch 8/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0658 - accuracy: 0.9792 - val_loss: 0.2927 - val_accuracy: 0.8333\n","Epoch 9/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0531 - accuracy: 0.9792 - val_loss: 0.1560 - val_accuracy: 1.0000\n","Epoch 10/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 1.0000\n","Epoch 11/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 1.0000\n","Epoch 12/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 1.0000\n","Epoch 13/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 1.0000\n","Epoch 14/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 1.0000\n","Epoch 15/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 1.0000\n","Epoch 16/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 1.0000\n","Epoch 17/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 1.0000\n","Epoch 18/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9167\n","Epoch 19/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 1.0000\n","Epoch 20/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9167\n","Epoch 21/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9167\n","Epoch 22/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 1.0000\n","Epoch 23/30\n","8/8 [==============================] - 18s 2s/step - loss: 9.9205e-04 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9167\n","Epoch 24/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9167\n","Epoch 25/30\n","8/8 [==============================] - 18s 2s/step - loss: 9.3466e-04 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9167\n","Epoch 26/30\n","8/8 [==============================] - 18s 2s/step - loss: 7.9662e-04 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9167\n","Epoch 27/30\n","8/8 [==============================] - 18s 2s/step - loss: 7.7861e-04 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9167\n","Epoch 28/30\n","8/8 [==============================] - 19s 2s/step - loss: 6.3159e-04 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9167\n","Epoch 29/30\n","8/8 [==============================] - 19s 2s/step - loss: 5.9940e-04 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9167\n","Epoch 30/30\n","8/8 [==============================] - 18s 2s/step - loss: 5.6465e-04 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9167\n","              precision    recall  f1-score   support\n","\n","           0     0.8333    1.0000    0.9091         5\n","           1     1.0000    0.8571    0.9231         7\n","\n","    accuracy                         0.9167        12\n","   macro avg     0.9167    0.9286    0.9161        12\n","weighted avg     0.9306    0.9167    0.9172        12\n","\n","fold  2  acc  0.9166666666666666  auc  0.9166666666666667  precision  0.9285714285714286  recall  0.9166666666666667  f1score  0.916083916083916\n","[]\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["8/8 [==============================] - 20s 2s/step - loss: 0.7297 - accuracy: 0.5833 - val_loss: 0.7762 - val_accuracy: 0.5000\n","Epoch 2/30\n","8/8 [==============================] - 20s 3s/step - loss: 0.6593 - accuracy: 0.6875 - val_loss: 0.6704 - val_accuracy: 0.5833\n","Epoch 3/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.4579 - accuracy: 0.9375 - val_loss: 0.6249 - val_accuracy: 0.5000\n","Epoch 4/30\n","8/8 [==============================] - 19s 2s/step - loss: 0.3172 - accuracy: 0.8750 - val_loss: 0.6144 - val_accuracy: 0.5833\n","Epoch 5/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.2380 - accuracy: 0.9167 - val_loss: 0.7907 - val_accuracy: 0.5833\n","Epoch 6/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.1285 - accuracy: 0.9792 - val_loss: 0.6683 - val_accuracy: 0.5833\n","Epoch 7/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0894 - accuracy: 0.9792 - val_loss: 0.6493 - val_accuracy: 0.5833\n","Epoch 8/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0707 - accuracy: 0.9792 - val_loss: 0.8970 - val_accuracy: 0.5833\n","Epoch 9/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0555 - accuracy: 0.9792 - val_loss: 1.2047 - val_accuracy: 0.5833\n","Epoch 10/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.5697 - val_accuracy: 0.8333\n","Epoch 11/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.5909 - val_accuracy: 0.5833\n","Epoch 12/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.9603 - val_accuracy: 0.5833\n","Epoch 13/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.6546 - val_accuracy: 0.5833\n","Epoch 14/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4895 - val_accuracy: 0.5833\n","Epoch 15/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5574 - val_accuracy: 0.5833\n","Epoch 16/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6148 - val_accuracy: 0.5833\n","Epoch 17/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6264 - val_accuracy: 0.5833\n","Epoch 18/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7451 - val_accuracy: 0.5833\n","Epoch 19/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7044 - val_accuracy: 0.5833\n","Epoch 20/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6689 - val_accuracy: 0.5833\n","Epoch 21/30\n","8/8 [==============================] - 18s 2s/step - loss: 9.2124e-04 - accuracy: 1.0000 - val_loss: 1.6947 - val_accuracy: 0.5833\n","Epoch 22/30\n","8/8 [==============================] - 18s 2s/step - loss: 7.8951e-04 - accuracy: 1.0000 - val_loss: 1.7539 - val_accuracy: 0.5833\n","Epoch 23/30\n","8/8 [==============================] - 18s 2s/step - loss: 6.8807e-04 - accuracy: 1.0000 - val_loss: 1.7461 - val_accuracy: 0.5833\n","Epoch 24/30\n","8/8 [==============================] - 18s 2s/step - loss: 6.2803e-04 - accuracy: 1.0000 - val_loss: 1.7199 - val_accuracy: 0.5833\n","Epoch 25/30\n","8/8 [==============================] - 17s 2s/step - loss: 5.5449e-04 - accuracy: 1.0000 - val_loss: 1.7818 - val_accuracy: 0.5833\n","Epoch 26/30\n","8/8 [==============================] - 17s 2s/step - loss: 5.0103e-04 - accuracy: 1.0000 - val_loss: 1.7961 - val_accuracy: 0.5833\n","Epoch 27/30\n","8/8 [==============================] - 18s 2s/step - loss: 4.4778e-04 - accuracy: 1.0000 - val_loss: 1.7746 - val_accuracy: 0.5833\n","Epoch 28/30\n","8/8 [==============================] - 17s 2s/step - loss: 4.1718e-04 - accuracy: 1.0000 - val_loss: 1.8290 - val_accuracy: 0.5833\n","Epoch 29/30\n","8/8 [==============================] - 17s 2s/step - loss: 3.7304e-04 - accuracy: 1.0000 - val_loss: 1.8280 - val_accuracy: 0.5833\n","Epoch 30/30\n","8/8 [==============================] - 17s 2s/step - loss: 3.4789e-04 - accuracy: 1.0000 - val_loss: 1.8293 - val_accuracy: 0.5833\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.5455    0.7059        11\n","           1     0.1667    1.0000    0.2857         1\n","\n","    accuracy                         0.5833        12\n","   macro avg     0.5833    0.7727    0.4958        12\n","weighted avg     0.9306    0.5833    0.6709        12\n","\n","fold  3  acc  0.5833333333333334  auc  0.5833333333333334  precision  0.7727272727272727  recall  0.5833333333333334  f1score  0.49579831932773105\n","[]\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["8/8 [==============================] - 19s 2s/step - loss: 0.6123 - accuracy: 0.6458 - val_loss: 0.4486 - val_accuracy: 0.7500\n","Epoch 2/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.3127 - accuracy: 0.9167 - val_loss: 0.2268 - val_accuracy: 1.0000\n","Epoch 3/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.1788 - accuracy: 0.9375 - val_loss: 0.1776 - val_accuracy: 0.9167\n","Epoch 4/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.1164 - accuracy: 0.9583 - val_loss: 0.2108 - val_accuracy: 0.8333\n","Epoch 5/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 1.0000\n","Epoch 6/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.7500\n","Epoch 7/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 1.0000\n","Epoch 8/30\n","8/8 [==============================] - 19s 2s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9167\n","Epoch 9/30\n","8/8 [==============================] - 19s 2s/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 1.0000\n","Epoch 10/30\n","8/8 [==============================] - 20s 3s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 1.0000\n","Epoch 11/30\n","8/8 [==============================] - 21s 3s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 1.0000\n","Epoch 12/30\n","8/8 [==============================] - 22s 3s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.8333\n","Epoch 13/30\n","8/8 [==============================] - 18s 2s/step - loss: 8.5278e-04 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 1.0000\n","Epoch 14/30\n","8/8 [==============================] - 18s 2s/step - loss: 6.2533e-04 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 1.0000\n","Epoch 15/30\n","8/8 [==============================] - 18s 2s/step - loss: 5.6441e-04 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 1.0000\n","Epoch 16/30\n","8/8 [==============================] - 18s 2s/step - loss: 4.5363e-04 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 1.0000\n","Epoch 17/30\n","8/8 [==============================] - 18s 2s/step - loss: 3.8491e-04 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 1.0000\n","Epoch 18/30\n","8/8 [==============================] - 17s 2s/step - loss: 3.4732e-04 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 1.0000\n","Epoch 19/30\n","8/8 [==============================] - 19s 2s/step - loss: 3.1570e-04 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 1.0000\n","Epoch 20/30\n","8/8 [==============================] - 20s 2s/step - loss: 2.9168e-04 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 1.0000\n","Epoch 21/30\n","8/8 [==============================] - 19s 2s/step - loss: 2.6830e-04 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 1.0000\n","Epoch 22/30\n","8/8 [==============================] - 18s 2s/step - loss: 2.4214e-04 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 1.0000\n","Epoch 23/30\n","8/8 [==============================] - 19s 2s/step - loss: 2.2821e-04 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 1.0000\n","Epoch 24/30\n","8/8 [==============================] - 18s 2s/step - loss: 2.2065e-04 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 1.0000\n","Epoch 25/30\n","8/8 [==============================] - 19s 2s/step - loss: 2.1151e-04 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 1.0000\n","Epoch 26/30\n","8/8 [==============================] - 18s 2s/step - loss: 1.8751e-04 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 1.0000\n","Epoch 27/30\n","8/8 [==============================] - 19s 2s/step - loss: 1.7342e-04 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 1.0000\n","Epoch 28/30\n","8/8 [==============================] - 19s 2s/step - loss: 1.6772e-04 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 1.0000\n","Epoch 29/30\n","8/8 [==============================] - 18s 2s/step - loss: 1.5885e-04 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 1.0000\n","Epoch 30/30\n","8/8 [==============================] - 17s 2s/step - loss: 1.5065e-04 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 1.0000\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdcdea62f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         6\n","           1     1.0000    1.0000    1.0000         6\n","\n","    accuracy                         1.0000        12\n","   macro avg     1.0000    1.0000    1.0000        12\n","weighted avg     1.0000    1.0000    1.0000        12\n","\n","fold  4  acc  1.0  auc  1.0  precision  1.0  recall  1.0  f1score  1.0\n","avg_acc =  0.85 avg_auc =  0.85\n","acc_all =  [0.91666667 0.83333333 0.91666667 0.58333333 1.        ]\n","auc_all =  [0.91666667 0.83333333 0.91666667 0.58333333 1.        ]\n","*********** dataset_name = dataset_1_connectivity_matrix.mat  *******************\n","number of classes:  2\n","[]\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["8/8 [==============================] - 19s 2s/step - loss: 0.6831 - accuracy: 0.6042 - val_loss: 0.4101 - val_accuracy: 0.9167\n","Epoch 2/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.2817 - accuracy: 0.9583 - val_loss: 0.2727 - val_accuracy: 0.9167\n","Epoch 3/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.1332 - accuracy: 0.9792 - val_loss: 0.2901 - val_accuracy: 0.8333\n","Epoch 4/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.1032 - accuracy: 0.9792 - val_loss: 0.3057 - val_accuracy: 0.9167\n","Epoch 5/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0824 - accuracy: 0.9792 - val_loss: 0.2134 - val_accuracy: 0.9167\n","Epoch 6/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0635 - accuracy: 0.9792 - val_loss: 0.3267 - val_accuracy: 0.9167\n","Epoch 7/30\n","8/8 [==============================] - 19s 2s/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9167\n","Epoch 8/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9167\n","Epoch 9/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9167\n","Epoch 10/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9167\n","Epoch 11/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9167\n","Epoch 12/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9167\n","Epoch 13/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9167\n","Epoch 14/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9167\n","Epoch 15/30\n","8/8 [==============================] - 18s 2s/step - loss: 9.8658e-04 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9167\n","Epoch 16/30\n","8/8 [==============================] - 19s 2s/step - loss: 8.7496e-04 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9167\n","Epoch 17/30\n","8/8 [==============================] - 19s 2s/step - loss: 7.7981e-04 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9167\n","Epoch 18/30\n","8/8 [==============================] - 18s 2s/step - loss: 7.2742e-04 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9167\n","Epoch 19/30\n","8/8 [==============================] - 18s 2s/step - loss: 6.7126e-04 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9167\n","Epoch 20/30\n","8/8 [==============================] - 18s 2s/step - loss: 5.9182e-04 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9167\n","Epoch 21/30\n","8/8 [==============================] - 18s 2s/step - loss: 5.3736e-04 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9167\n","Epoch 22/30\n","8/8 [==============================] - 23s 3s/step - loss: 4.9063e-04 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9167\n","Epoch 23/30\n","8/8 [==============================] - 18s 2s/step - loss: 4.6497e-04 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9167\n","Epoch 24/30\n","8/8 [==============================] - 18s 2s/step - loss: 4.2950e-04 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9167\n","Epoch 25/30\n","8/8 [==============================] - 17s 2s/step - loss: 3.9797e-04 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9167\n","Epoch 26/30\n","8/8 [==============================] - 17s 2s/step - loss: 3.7310e-04 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9167\n","Epoch 27/30\n","8/8 [==============================] - 17s 2s/step - loss: 3.4467e-04 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9167\n","Epoch 28/30\n","8/8 [==============================] - 19s 2s/step - loss: 3.2907e-04 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9167\n","Epoch 29/30\n","8/8 [==============================] - 19s 2s/step - loss: 3.0543e-04 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9167\n","Epoch 30/30\n","8/8 [==============================] - 19s 2s/step - loss: 2.9154e-04 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9167\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdcd608add0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0     1.0000    0.8571    0.9231         7\n","           1     0.8333    1.0000    0.9091         5\n","\n","    accuracy                         0.9167        12\n","   macro avg     0.9167    0.9286    0.9161        12\n","weighted avg     0.9306    0.9167    0.9172        12\n","\n","fold  0  acc  0.9166666666666666  auc  0.9166666666666667  precision  0.9285714285714286  recall  0.9166666666666667  f1score  0.916083916083916\n","[]\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["8/8 [==============================] - 19s 2s/step - loss: 0.6767 - accuracy: 0.6458 - val_loss: 0.6584 - val_accuracy: 0.7500\n","Epoch 2/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.4161 - accuracy: 0.9167 - val_loss: 1.0618 - val_accuracy: 0.3333\n","Epoch 3/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.4033 - accuracy: 0.7708 - val_loss: 1.1934 - val_accuracy: 0.7500\n","Epoch 4/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.2071 - accuracy: 0.9792 - val_loss: 1.3355 - val_accuracy: 0.6667\n","Epoch 5/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0883 - accuracy: 0.9792 - val_loss: 1.7010 - val_accuracy: 0.7500\n","Epoch 6/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0493 - accuracy: 0.9792 - val_loss: 1.7042 - val_accuracy: 0.7500\n","Epoch 7/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 1.8335 - val_accuracy: 0.6667\n","Epoch 8/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.0906 - val_accuracy: 0.7500\n","Epoch 9/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.2859 - val_accuracy: 0.7500\n","Epoch 10/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.3045 - val_accuracy: 0.7500\n","Epoch 11/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3850 - val_accuracy: 0.7500\n","Epoch 12/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4513 - val_accuracy: 0.7500\n","Epoch 13/30\n","8/8 [==============================] - 19s 2s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5200 - val_accuracy: 0.7500\n","Epoch 14/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5787 - val_accuracy: 0.7500\n","Epoch 15/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6084 - val_accuracy: 0.7500\n","Epoch 16/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6228 - val_accuracy: 0.7500\n","Epoch 17/30\n","8/8 [==============================] - 17s 2s/step - loss: 8.8532e-04 - accuracy: 1.0000 - val_loss: 2.6554 - val_accuracy: 0.7500\n","Epoch 18/30\n","8/8 [==============================] - 17s 2s/step - loss: 7.5066e-04 - accuracy: 1.0000 - val_loss: 2.6962 - val_accuracy: 0.7500\n","Epoch 19/30\n","8/8 [==============================] - 18s 2s/step - loss: 6.6721e-04 - accuracy: 1.0000 - val_loss: 2.7301 - val_accuracy: 0.7500\n","Epoch 20/30\n","8/8 [==============================] - 19s 2s/step - loss: 5.8718e-04 - accuracy: 1.0000 - val_loss: 2.7052 - val_accuracy: 0.7500\n","Epoch 21/30\n","8/8 [==============================] - 19s 2s/step - loss: 5.2263e-04 - accuracy: 1.0000 - val_loss: 2.7223 - val_accuracy: 0.7500\n","Epoch 22/30\n","8/8 [==============================] - 24s 3s/step - loss: 4.6126e-04 - accuracy: 1.0000 - val_loss: 2.7267 - val_accuracy: 0.7500\n","Epoch 23/30\n","8/8 [==============================] - 18s 2s/step - loss: 4.2355e-04 - accuracy: 1.0000 - val_loss: 2.7083 - val_accuracy: 0.7500\n","Epoch 24/30\n","8/8 [==============================] - 18s 2s/step - loss: 3.8575e-04 - accuracy: 1.0000 - val_loss: 2.7354 - val_accuracy: 0.7500\n","Epoch 25/30\n","8/8 [==============================] - 22s 3s/step - loss: 3.6302e-04 - accuracy: 1.0000 - val_loss: 2.6870 - val_accuracy: 0.7500\n","Epoch 26/30\n","8/8 [==============================] - 19s 2s/step - loss: 3.3102e-04 - accuracy: 1.0000 - val_loss: 2.6906 - val_accuracy: 0.7500\n","Epoch 27/30\n","8/8 [==============================] - 19s 2s/step - loss: 2.9990e-04 - accuracy: 1.0000 - val_loss: 2.6928 - val_accuracy: 0.7500\n","Epoch 28/30\n","8/8 [==============================] - 18s 2s/step - loss: 2.7324e-04 - accuracy: 1.0000 - val_loss: 2.6563 - val_accuracy: 0.7500\n","Epoch 29/30\n","8/8 [==============================] - 18s 2s/step - loss: 2.5897e-04 - accuracy: 1.0000 - val_loss: 2.6352 - val_accuracy: 0.7500\n","Epoch 30/30\n","8/8 [==============================] - 18s 2s/step - loss: 2.4207e-04 - accuracy: 1.0000 - val_loss: 2.6260 - val_accuracy: 0.7500\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.6667    0.8000         9\n","           1     0.5000    1.0000    0.6667         3\n","\n","    accuracy                         0.7500        12\n","   macro avg     0.7500    0.8333    0.7333        12\n","weighted avg     0.8750    0.7500    0.7667        12\n","\n","fold  1  acc  0.75  auc  0.75  precision  0.8333333333333333  recall  0.75  f1score  0.7333333333333334\n","[]\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["8/8 [==============================] - 19s 2s/step - loss: 0.7150 - accuracy: 0.7083 - val_loss: 0.5422 - val_accuracy: 0.8333\n","Epoch 2/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.4643 - accuracy: 0.8750 - val_loss: 0.4636 - val_accuracy: 0.7500\n","Epoch 3/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.2974 - accuracy: 0.9583 - val_loss: 0.2940 - val_accuracy: 0.9167\n","Epoch 4/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.1692 - accuracy: 0.9583 - val_loss: 0.3314 - val_accuracy: 0.8333\n","Epoch 5/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.1186 - accuracy: 0.9583 - val_loss: 0.1707 - val_accuracy: 1.0000\n","Epoch 6/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0703 - accuracy: 0.9583 - val_loss: 0.2825 - val_accuracy: 0.9167\n","Epoch 7/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 1.0000\n","Epoch 8/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9167\n","Epoch 9/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 0.9167\n","Epoch 10/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9167\n","Epoch 11/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9167\n","Epoch 12/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9167\n","Epoch 13/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9167\n","Epoch 14/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 1.0000\n","Epoch 15/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9167\n","Epoch 16/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 1.0000\n","Epoch 17/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 1.0000\n","Epoch 18/30\n","8/8 [==============================] - 17s 2s/step - loss: 8.4872e-04 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9167\n","Epoch 19/30\n","8/8 [==============================] - 18s 2s/step - loss: 7.7945e-04 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9167\n","Epoch 20/30\n","8/8 [==============================] - 17s 2s/step - loss: 6.7689e-04 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9167\n","Epoch 21/30\n","8/8 [==============================] - 17s 2s/step - loss: 6.0448e-04 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 1.0000\n","Epoch 22/30\n","8/8 [==============================] - 19s 2s/step - loss: 5.6114e-04 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 1.0000\n","Epoch 23/30\n","8/8 [==============================] - 18s 2s/step - loss: 5.0437e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9167\n","Epoch 24/30\n","8/8 [==============================] - 18s 2s/step - loss: 4.5344e-04 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9167\n","Epoch 25/30\n","8/8 [==============================] - 18s 2s/step - loss: 4.1932e-04 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9167\n","Epoch 26/30\n","8/8 [==============================] - 17s 2s/step - loss: 3.9172e-04 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 1.0000\n","Epoch 27/30\n","8/8 [==============================] - 18s 2s/step - loss: 3.5818e-04 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 1.0000\n","Epoch 28/30\n","8/8 [==============================] - 18s 2s/step - loss: 3.4421e-04 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 1.0000\n","Epoch 29/30\n","8/8 [==============================] - 22s 3s/step - loss: 3.1685e-04 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9167\n","Epoch 30/30\n","8/8 [==============================] - 17s 2s/step - loss: 2.8294e-04 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 1.0000\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         6\n","           1     1.0000    1.0000    1.0000         6\n","\n","    accuracy                         1.0000        12\n","   macro avg     1.0000    1.0000    1.0000        12\n","weighted avg     1.0000    1.0000    1.0000        12\n","\n","fold  2  acc  1.0  auc  1.0  precision  1.0  recall  1.0  f1score  1.0\n","[]\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["8/8 [==============================] - 19s 2s/step - loss: 0.6072 - accuracy: 0.7708 - val_loss: 0.6833 - val_accuracy: 0.5833\n","Epoch 2/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.2455 - accuracy: 0.9375 - val_loss: 0.5662 - val_accuracy: 0.5833\n","Epoch 3/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.1028 - accuracy: 0.9792 - val_loss: 0.5862 - val_accuracy: 0.5833\n","Epoch 4/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0613 - accuracy: 0.9792 - val_loss: 1.3285 - val_accuracy: 0.5833\n","Epoch 5/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.6207 - val_accuracy: 0.6667\n","Epoch 6/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.1372 - val_accuracy: 0.5833\n","Epoch 7/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3837 - val_accuracy: 0.5833\n","Epoch 8/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3666 - val_accuracy: 0.5833\n","Epoch 9/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4930 - val_accuracy: 0.5833\n","Epoch 10/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2189 - val_accuracy: 0.5833\n","Epoch 11/30\n","8/8 [==============================] - 17s 2s/step - loss: 9.5906e-04 - accuracy: 1.0000 - val_loss: 1.2493 - val_accuracy: 0.5833\n","Epoch 12/30\n","8/8 [==============================] - 19s 2s/step - loss: 7.5468e-04 - accuracy: 1.0000 - val_loss: 1.4842 - val_accuracy: 0.5833\n","Epoch 13/30\n","8/8 [==============================] - 18s 2s/step - loss: 8.3969e-04 - accuracy: 1.0000 - val_loss: 1.3721 - val_accuracy: 0.5833\n","Epoch 14/30\n","8/8 [==============================] - 19s 2s/step - loss: 6.1835e-04 - accuracy: 1.0000 - val_loss: 1.2903 - val_accuracy: 0.5833\n","Epoch 15/30\n","8/8 [==============================] - 18s 2s/step - loss: 5.1646e-04 - accuracy: 1.0000 - val_loss: 1.4854 - val_accuracy: 0.5833\n","Epoch 16/30\n","8/8 [==============================] - 18s 2s/step - loss: 4.7864e-04 - accuracy: 1.0000 - val_loss: 1.4788 - val_accuracy: 0.5833\n","Epoch 17/30\n","8/8 [==============================] - 18s 2s/step - loss: 4.3649e-04 - accuracy: 1.0000 - val_loss: 1.4288 - val_accuracy: 0.5833\n","Epoch 18/30\n","8/8 [==============================] - 17s 2s/step - loss: 3.9247e-04 - accuracy: 1.0000 - val_loss: 1.4964 - val_accuracy: 0.5833\n","Epoch 19/30\n","8/8 [==============================] - 17s 2s/step - loss: 3.6901e-04 - accuracy: 1.0000 - val_loss: 1.4538 - val_accuracy: 0.5833\n","Epoch 20/30\n","8/8 [==============================] - 19s 2s/step - loss: 3.4883e-04 - accuracy: 1.0000 - val_loss: 1.4266 - val_accuracy: 0.5833\n","Epoch 21/30\n","8/8 [==============================] - 18s 2s/step - loss: 3.1075e-04 - accuracy: 1.0000 - val_loss: 1.4934 - val_accuracy: 0.5833\n","Epoch 22/30\n","8/8 [==============================] - 18s 2s/step - loss: 2.9606e-04 - accuracy: 1.0000 - val_loss: 1.5035 - val_accuracy: 0.5833\n","Epoch 23/30\n","8/8 [==============================] - 18s 2s/step - loss: 2.6895e-04 - accuracy: 1.0000 - val_loss: 1.5664 - val_accuracy: 0.5833\n","Epoch 24/30\n","8/8 [==============================] - 18s 2s/step - loss: 2.5681e-04 - accuracy: 1.0000 - val_loss: 1.5303 - val_accuracy: 0.5833\n","Epoch 25/30\n","8/8 [==============================] - 19s 2s/step - loss: 2.4332e-04 - accuracy: 1.0000 - val_loss: 1.4936 - val_accuracy: 0.5833\n","Epoch 26/30\n","8/8 [==============================] - 18s 2s/step - loss: 2.2518e-04 - accuracy: 1.0000 - val_loss: 1.5592 - val_accuracy: 0.5833\n","Epoch 27/30\n","8/8 [==============================] - 17s 2s/step - loss: 2.1107e-04 - accuracy: 1.0000 - val_loss: 1.5407 - val_accuracy: 0.5833\n","Epoch 28/30\n","8/8 [==============================] - 17s 2s/step - loss: 2.0061e-04 - accuracy: 1.0000 - val_loss: 1.5223 - val_accuracy: 0.5833\n","Epoch 29/30\n","8/8 [==============================] - 17s 2s/step - loss: 1.8862e-04 - accuracy: 1.0000 - val_loss: 1.5766 - val_accuracy: 0.5833\n","Epoch 30/30\n","8/8 [==============================] - 18s 2s/step - loss: 1.7690e-04 - accuracy: 1.0000 - val_loss: 1.5718 - val_accuracy: 0.5833\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.5455    0.7059        11\n","           1     0.1667    1.0000    0.2857         1\n","\n","    accuracy                         0.5833        12\n","   macro avg     0.5833    0.7727    0.4958        12\n","weighted avg     0.9306    0.5833    0.6709        12\n","\n","fold  3  acc  0.5833333333333334  auc  0.5833333333333334  precision  0.7727272727272727  recall  0.5833333333333334  f1score  0.49579831932773105\n","[]\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["8/8 [==============================] - 18s 2s/step - loss: 0.8473 - accuracy: 0.4792 - val_loss: 0.6362 - val_accuracy: 0.6667\n","Epoch 2/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.5754 - accuracy: 0.7083 - val_loss: 0.4961 - val_accuracy: 0.6667\n","Epoch 3/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.4215 - accuracy: 0.8333 - val_loss: 0.3648 - val_accuracy: 0.8333\n","Epoch 4/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.2787 - accuracy: 0.9167 - val_loss: 0.2576 - val_accuracy: 0.9167\n","Epoch 5/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.1735 - accuracy: 0.9792 - val_loss: 0.1596 - val_accuracy: 1.0000\n","Epoch 6/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.1258 - accuracy: 0.9583 - val_loss: 0.1613 - val_accuracy: 1.0000\n","Epoch 7/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0895 - accuracy: 0.9792 - val_loss: 0.1127 - val_accuracy: 1.0000\n","Epoch 8/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0636 - accuracy: 0.9792 - val_loss: 0.1424 - val_accuracy: 1.0000\n","Epoch 9/30\n","8/8 [==============================] - 19s 2s/step - loss: 0.0506 - accuracy: 0.9792 - val_loss: 0.1281 - val_accuracy: 0.9167\n","Epoch 10/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0486 - accuracy: 0.9792 - val_loss: 0.1623 - val_accuracy: 1.0000\n","Epoch 11/30\n","8/8 [==============================] - 17s 2s/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 0.9167\n","Epoch 12/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 1.0000\n","Epoch 13/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 1.0000\n","Epoch 14/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 0.9167\n","Epoch 15/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 0.9167\n","Epoch 16/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 1.0000\n","Epoch 17/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 1.0000\n","Epoch 18/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 1.0000\n","Epoch 19/30\n","8/8 [==============================] - 18s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 1.0000\n","Epoch 20/30\n","8/8 [==============================] - 19s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 1.0000\n","Epoch 21/30\n","8/8 [==============================] - 18s 2s/step - loss: 9.3071e-04 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 1.0000\n","Epoch 22/30\n","8/8 [==============================] - 18s 2s/step - loss: 8.3530e-04 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9167\n","Epoch 23/30\n","8/8 [==============================] - 17s 2s/step - loss: 7.6443e-04 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9167\n","Epoch 24/30\n","8/8 [==============================] - 17s 2s/step - loss: 7.1983e-04 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 1.0000\n","Epoch 25/30\n","8/8 [==============================] - 17s 2s/step - loss: 6.3871e-04 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 1.0000\n","Epoch 26/30\n","8/8 [==============================] - 17s 2s/step - loss: 5.9173e-04 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9167\n","Epoch 27/30\n","8/8 [==============================] - 17s 2s/step - loss: 5.4803e-04 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9167\n","Epoch 28/30\n","8/8 [==============================] - 17s 2s/step - loss: 5.0863e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 1.0000\n","Epoch 29/30\n","8/8 [==============================] - 18s 2s/step - loss: 4.7251e-04 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 1.0000\n","Epoch 30/30\n","8/8 [==============================] - 18s 2s/step - loss: 4.3515e-04 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 1.0000\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         6\n","           1     1.0000    1.0000    1.0000         6\n","\n","    accuracy                         1.0000        12\n","   macro avg     1.0000    1.0000    1.0000        12\n","weighted avg     1.0000    1.0000    1.0000        12\n","\n","fold  4  acc  1.0  auc  1.0  precision  1.0  recall  1.0  f1score  1.0\n","avg_acc =  0.85 avg_auc =  0.85\n","acc_all =  [0.91666667 0.75       1.         0.58333333 1.        ]\n","auc_all =  [0.91666667 0.75       1.         0.58333333 1.        ]\n","Accuracy from all runs:  [array([0.91666667, 0.83333333, 0.91666667, 0.58333333, 1.        ]), array([0.91666667, 0.75      , 1.        , 0.58333333, 1.        ])]\n","AUC from all runs:  [array([0.91666667, 0.83333333, 0.91666667, 0.58333333, 1.        ]), array([0.91666667, 0.75      , 1.        , 0.58333333, 1.        ])]\n","Average acc =  0.85\n","STD =  0.15275252316519464\n","Average auc =  0.85\n","STD =  0.15275252316519466\n","Average f1score =  0.8306515053573877\n","STD =  0.18484159691925817\n"]}],"source":["\n","!pip install keract\n","\n","%load_ext tensorboard\n","import tensorflow as tf\n","import datetime, os\n","import tensorflow.keras\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy.io\n","from keras import backend as K\n","from keract import get_activations\n","import keract\n","\n","\n","\n","def initialize_model(num_classes):\n","\n","    model = models.Sequential()\n","    model.add(layers.Conv2D(6, (6, 6), activation='relu', input_shape = (600,600,1)))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","\n","    model.add(layers.Conv2D(6, (6, 6), activation='relu'))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","\n","    # model.add(layers.Conv2D(6, (6, 6), activation='relu'))\n","    # model.add(layers.MaxPooling2D((2, 2)))\n","\n","    # model.add(layers.Conv2D(6, (6, 6), activation='relu'))\n","    # model.add(layers.MaxPooling2D((2, 2)))\n","\n","    # model.add(layers.Conv2D(6, (6, 6), activation='relu'))\n","    # model.add(layers.MaxPooling2D((2, 2)))\n","\n","    # model.add(layers.Conv2D(6, (6, 6), activation='relu'))\n","    # model.add(layers.MaxPooling2D((2, 2)))\n","\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(64, activation='relu'))\n","    model.add(layers.Dense(num_classes, activation='softmax'))\n","\n","    \n","    return model\n","\n","permute_ratio = 0\n","\n","\n","# os.chdir('/content/gdrive/My Drive/Graph_based_methods/Graph_Transformer/dataset/Features_Omar_new')\n","\n","# dataset = data_with_\n","# dataset_name = dataset + '_RBF_manual_matrix.mat'\n","# dataset_name = dataset + '_RBF_plus_connectivity_manual_matrix.mat'\n","# dataset_name = dataset + '_RBF_based_on_connectivity.mat'\n","# dataset_name = dataset + '_connectivity_matrix.mat'\n","\n","def run_CNN():\n","  mat = scipy.io.loadmat(dataset_name)\n","  X = mat['X_feature_tensor']\n","\n","  ndims_X = np.ndim(X)\n","\n","  if(ndims_X == 2):\n","    X_feature = Vec2Matrix(X)\n","  elif(ndims_X == 3):\n","    X_feature = X\n","\n","  num_graph,W,H = X_feature.shape\n","  A_all = []\n","\n","  # for i in range(num_graph):\n","  #   X_i = X_feature[i,:,:].copy()\n","  #   X_i_permute,A_i = permute_matrix(X_i, permute_ratio)\n","  #   X_feature[i,:,:] = X_i_permute\n","  #   A_all.append(A_i)\n","\n","\n","  label_name = 'label_'+ dataset + '.mat'\n","  mat = scipy.io.loadmat(label_name)\n","  label_all = mat['label_all'][0]\n","\n","  print('*********** dataset_name =', dataset_name,' *******************')\n","  classes = np.unique(label_all)\n","  num_classes = classes.size\n","  print('number of classes: ', num_classes)\n","\n","\n","  predicted_labels = []\n","  acc_all = []\n","  auc_all = []\n","  f1score_all = []\n","\n","  for fold_idx in range(5):    \n","      train_idx, test_idx = separate_data_idx(label_all, fold_idx)\n","      intersect = np.intersect1d(train_idx, test_idx)\n","      print(intersect)\n","\n","      train_embeddings = X_feature[train_idx,:,:]\n","      test_embeddings = X_feature[test_idx,:,:]\n","      train_labels = label_all[train_idx]\n","      test_labels = label_all[test_idx]\n","\n","      N, H, W = train_embeddings.shape\n","      train_embeddings = np.reshape(train_embeddings, [N,H,W,1])\n","\n","\n","      N, H, W = test_embeddings.shape\n","      test_embeddings = np.reshape(test_embeddings, [N,H,W,1])\n","\n","\n","      model = initialize_model(num_classes)\n","\n","      model.compile(optimizer='adam',\n","                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                    metrics=['accuracy'])\n","      \n","      logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","      tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n","\n","      model.fit(x=train_embeddings, \n","              y=train_labels, \n","              epochs = 30,\n","              batch_size = 6, \n","              validation_data=(test_embeddings, test_labels), \n","              callbacks=[tensorboard_callback], verbose = 1)\n","      \n","      predictions = model.predict(test_embeddings)\n","\n","      predicted_labals = np.argmax(predictions, axis = -1)\n","\n","      acc, auc, precision, recall, f1score = calculate_acc(predicted_labals, test_labels)\n","\n","      auc_all.append(auc)\n","      acc_all.append(acc) \n","      f1score_all.append(f1score)\n","\n","      print('fold ', fold_idx, ' acc ', acc, ' auc ', auc, ' precision ', precision, ' recall ', recall, ' f1score ', f1score) \n","      \n","      #### Predict_with_Logistic_regression\n","      # extractor = tensorflow.keras.Model(inputs=model.inputs,\n","      #                     outputs=[layer.output for layer in model.layers])\n","\n","      # features = extractor(X_feature)\n","\n","      # X_feature_new = features[5]\n","\n","      # X_feature_new = np.array(X_feature_new)\n","\n","      # train_embeddings = X_feature_new[train_idx,:]\n","      # test_embeddings = X_feature_new[test_idx,:]\n","      # train_labels = label_all[train_idx]\n","      # test_labels = label_all[test_idx]\n","\n","      # cls = LogisticRegression(tol=0.001, max_iter = 2000)\n","      # cls.fit(train_embeddings, train_labels)\n","\n","      # predicted_labals = cls.predict(test_embeddings)\n","\n","      # acc, auc = calculate_acc(predicted_labals, test_labels)\n","      # print('fold ', fold_idx, ' acc ', acc, ' auc ', auc)\n","\n","      # auc_all.append(auc)\n","      # acc_all.append(acc) \n","\n","      ## Predict with KNN\n","      # extractor = tensorflow.keras.Model(inputs=model.inputs,\n","      #                     outputs=[layer.output for layer in model.layers])\n","\n","      # features = extractor(X_feature)\n","\n","      # X_feature_new = features[7]\n","      # X_feature_new = np.array(X_feature_new)\n","\n","      # predicted_labals = Knn_classifier(X_feature_new, label_all, train_idx, test_idx)\n","      # acc, auc = calculate_acc(predicted_labals, test_labels)\n","\n","      # auc_all.append(auc)\n","      # acc_all.append(acc)\n","\n","      # print('fold ', fold_idx, ' acc ', acc, ' auc ', auc) \n","\n","  acc_all = np.array(acc_all)\n","  auc_all = np.array(auc_all)\n","  f1score_all = np.array(f1score_all)\n","\n","  print('avg_acc = ',np.mean(acc_all), 'avg_auc = ',np.mean(auc_all))\n","  print('acc_all = ', acc_all)   \n","  print('auc_all = ', auc_all)   \n","\n","  return acc_all, auc_all, f1score_all\n","\n","total_acc = []\n","total_auc = []\n","total_f1score = []\n","iter = 2\n","for i in range(iter):\n","  acc_all,auc_all, f1score_all = run_CNN()\n","  total_acc.append(acc_all)\n","  total_auc.append(auc_all)\n","  total_f1score.append(f1score_all)\n","\n","print_results(total_acc, total_auc, total_f1score)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":829},"executionInfo":{"elapsed":4837,"status":"error","timestamp":1664394104387,"user":{"displayName":"Justin Tam","userId":"05887593918509535140"},"user_tz":240},"id":"JjRxEpbUUgp3","outputId":"cc51938f-6241-4ec1-f168-55031d3d90e7"},"outputs":[{"name":"stderr","output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-1-be5f97d4d472>\", line 3, in <module>\n","    extractor = tensorflow.keras.Model(inputs=model.inputs,\n","NameError: name 'model' is not defined\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'NameError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 319, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/usr/lib/python3.7/inspect.py\", line 739, in getmodule\n","    f = getabsfile(module)\n","  File \"/usr/lib/python3.7/inspect.py\", line 709, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.7/posixpath.py\", line 385, in abspath\n","    return normpath(path)\n","  File \"/usr/lib/python3.7/posixpath.py\", line 366, in normpath\n","    new_comps.append(comp)\n","KeyboardInterrupt\n"]},{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"]}],"source":["import tensorflow.keras\n","\n","extractor = tensorflow.keras.Model(inputs=model.inputs,\n","                        outputs=[layer.output for layer in model.layers])\n","\n","features = extractor(X_feature)\n","\n","X = features[5]\n","\n","print(X.shape)\n","\n","\n","visualize_with_tSNE(X, label_all)\n","\n","# X_feature_new = np.array(X)\n","# print(X.shape)\n","# auc_all = []\n","# acc_all = []\n","# # ##**** Logistic Regression **** #####\n","# for fold_idx in range(5):\n","#     train_idx, test_idx = separate_data_idx(label_all, fold_idx)\n","#     train_embeddings = X_feature_new[train_idx,:]\n","#     test_embeddings = X_feature_new[test_idx,:]\n","#     train_labels = label_all[train_idx]\n","#     test_labels = label_all[test_idx]\n","\n","\n","\n","#     cls = LogisticRegression(tol=0.001, max_iter = 2000)\n","#     cls.fit(train_embeddings, train_labels)\n","#     ACC = cls.score(test_embeddings, test_labels)\n","\n","#     predicted = cls.predict(test_embeddings)\n","#     predicted_labels.append(predicted)\n","\n","#     acc, auc = calculate_acc(predicted, test_labels)\n","\n","#     print('fold ', fold_idx, ' acc ', ACC, ' auc ', auc) \n","\n","#     auc_all.append(auc)\n","#     acc_all.append(acc)\n","\n","# acc_all = np.array(acc_all)\n","# auc_all = np.array(auc_all)\n","\n","# print('mean_acc = ', np.mean(acc_all))\n","\n","# print('acc_all = ', acc_all)   \n","\n","# print('auc_all = ', auc_all) \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wXyjc3YSxJRO"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Fixing random state for reproducibility\n","np.random.seed(19680801)\n","\n","\n","# N = 10\n","# r0 = 0.6\n","# x = 0.9 * np.random.rand(N)\n","# y = 0.9 * np.random.rand(N)\n","# area = (20 * np.random.rand(N))**2  # 0 to 10 point radii\n","# c = np.sqrt(area)\n","# r = np.sqrt(x ** 2 + y ** 2)\n","# area1 = np.ma.masked_where(r < r0, area)\n","# area2 = np.ma.masked_where(r >= r0, area)\n","# plt.scatter(x, y, s=area1, marker='^', c=c)\n","# plt.scatter(x, y, s=area2, marker='o', c=c)\n","# # Show the boundary between the regions:\n","# theta = np.arange(0, np.pi / 2, 0.01)\n","# plt.plot(r0 * np.cos(theta), r0 * np.sin(theta))\n","\n","# plt.show()\n","\n","\n","x = np.random.rand(10,1)\n","y = np.random.rand(10,1)\n","plt.scatter(x, y, marker='^')\n","plt.scatter(x+1, y+1, marker='o')\n","plt.show()\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["y45Q0HJanW8L","lHd7IYzkkdsm","lTizzhHQLLi0","XWTNBL8QntFV","F5CN2etPIXdR","Mi52pXK6dbzW","xg-e8cPJk2Fh","GTWAzqOuq3jf","qD2eFV1UnYx1","zWn6veyhwIKV"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
